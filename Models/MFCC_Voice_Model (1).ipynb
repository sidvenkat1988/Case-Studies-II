{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MFCC Voice Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "64-A_21H33UL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af86d04b-3cab-4aaf-a423-b8341ba07743"
      },
      "source": [
        "%cd drive/My\\ Drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXHqZ_354BN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8f75edd-8c84-488d-e0fa-597b07101ae7"
      },
      "source": [
        "%cd case\\ studies\\ 2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/case studies 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32yyvYW74C4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed8c99be-f4b7-43e3-c183-ad47a5bcc02b"
      },
      "source": [
        "%cd Models/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/case studies 2/Models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa-VdTA84EMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d390de9d-0c6d-406c-de93-bf92116d9b52"
      },
      "source": [
        "%cd Voice\\ Models"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/case studies 2/Models/Voice Models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hecbAhJT4Fjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25a685c3-67b7-4014-eeea-145958a0085e"
      },
      "source": [
        "%cd MFCC/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/case studies 2/Models/Voice Models/MFCC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYz-NXnk4HyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eab852c-8f5a-4dbf-f423-fc56c4010f9e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_data.npy  test_label.npy  train_data.npy  train_label.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyYv9_wO4ImO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "3bf20cb8-0fcc-44c1-85e7-56fed767baef"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Flatten, BatchNormalization, Activation\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1gSMkwo5C8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkbqYxxm4MQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.load('train_data.npy', allow_pickle=True)\n",
        "train_labels = np.load('train_label.npy', allow_pickle = True)\n",
        "test_data = np.load('test_data.npy', allow_pickle = True)\n",
        "test_labels = np.load('test_label.npy', allow_pickle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8WwyBPi4S7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.DataFrame(columns = ['train_labels'])\n",
        "train_df['train_labels'] = train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR4oCTrm4ZX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.DataFrame(columns = ['test_labels'])\n",
        "test_df['test_labels'] = test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el3zBnFm4bwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train_data\n",
        "X_test = test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2t99l0Y41zB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2HGY75u44V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZKgaaGV5RtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X[:6400]\n",
        "X_val = X[6400:]\n",
        "y_train = y[:6400]\n",
        "y_val = y[6400:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opTI0lHv48wQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y_train = to_categorical(lb.fit_transform(y_train))\n",
        "y_val = to_categorical(lb.fit_transform(y_val))\n",
        "y_test = to_categorical(lb.fit_transform(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoL0c1kj6Ik2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7620464-b6f0-4c85-f98f-3574e7b20618"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6400, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhjjhlFL6Kdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e52c11b-741b-41c0-fa9a-1dbc5070360d"
      },
      "source": [
        "y_val.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDV5t3cQ6NFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "532ee934-0cd3-40e7-abe5-255a9facf45f"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifZZMZ5y7RYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ss = StandardScaler()\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_val = ss.transform(X_val)\n",
        "X_test = ss.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVLmkNlo-mfL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bae3dbf3-c0f2-45c6-cf24-68f236757b2b"
      },
      "source": [
        "input = Input(shape = (40, ))\n",
        "x = Dense(128, activation = 'relu')(input)\n",
        "x = Dense(128, activation = 'relu')(x)\n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "encoded = Dense(32, activation = 'relu')(x)\n",
        "x = Dense(64, activation = 'relu')(encoded)\n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "x = Dense(128, activation = 'relu')(x)\n",
        "x = Dense(128, activation = 'relu')(x)\n",
        "x = Dense(40, activation = 'softmax')(x)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY53e3oJ-uKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "bfee5b55-6681-4e95-bc68-c0daab5e2931"
      },
      "source": [
        "autoencoder = Model(input, x)\n",
        "autoencoder.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeTSEp3g-2tS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "7a4dc7e7-77d7-4656-ecf6-7afcbed7478b"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               5248      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 40)                5160      \n",
            "=================================================================\n",
            "Total params: 72,520\n",
            "Trainable params: 72,520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRZ9mn_h-5qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = 'voice_autoencoder.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK2LwHJN-9VT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43547ea9-e214-4b53-ee84-c058512d70c0"
      },
      "source": [
        "autoencoder_train = autoencoder.fit(X_train, X_train, epochs = 100, batch_size = 16, verbose = 1, callbacks = callbacks_list, validation_data = [X_val, X_val])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "6400/6400 [==============================] - 12s 2ms/step - loss: -125.6289 - acc: 0.0712 - val_loss: -147.2751 - val_acc: 0.0956\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.09563, saving model to voice_autoencoder.h5\n",
            "Epoch 2/100\n",
            "6400/6400 [==============================] - 3s 529us/step - loss: -147.7682 - acc: 0.1113 - val_loss: -155.3511 - val_acc: 0.1425\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.09563 to 0.14250, saving model to voice_autoencoder.h5\n",
            "Epoch 3/100\n",
            "6400/6400 [==============================] - 3s 528us/step - loss: -154.4807 - acc: 0.1280 - val_loss: -160.1229 - val_acc: 0.1344\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.14250\n",
            "Epoch 4/100\n",
            "6400/6400 [==============================] - 3s 537us/step - loss: -159.2281 - acc: 0.1531 - val_loss: -165.9257 - val_acc: 0.1638\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.14250 to 0.16375, saving model to voice_autoencoder.h5\n",
            "Epoch 5/100\n",
            "6400/6400 [==============================] - 3s 542us/step - loss: -163.7015 - acc: 0.1800 - val_loss: -168.9071 - val_acc: 0.1819\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.16375 to 0.18188, saving model to voice_autoencoder.h5\n",
            "Epoch 6/100\n",
            "6400/6400 [==============================] - 3s 537us/step - loss: -166.4639 - acc: 0.1778 - val_loss: -170.1124 - val_acc: 0.1800\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.18188\n",
            "Epoch 7/100\n",
            "6400/6400 [==============================] - 3s 534us/step - loss: -167.9312 - acc: 0.1797 - val_loss: -172.0382 - val_acc: 0.1669\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.18188\n",
            "Epoch 8/100\n",
            "6400/6400 [==============================] - 3s 526us/step - loss: -169.6809 - acc: 0.1941 - val_loss: -172.5326 - val_acc: 0.1625\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.18188\n",
            "Epoch 9/100\n",
            "6400/6400 [==============================] - 3s 528us/step - loss: -171.4286 - acc: 0.2002 - val_loss: -175.3031 - val_acc: 0.1913\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.18188 to 0.19125, saving model to voice_autoencoder.h5\n",
            "Epoch 10/100\n",
            "6400/6400 [==============================] - 3s 534us/step - loss: -173.2122 - acc: 0.2130 - val_loss: -177.3404 - val_acc: 0.2119\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.19125 to 0.21188, saving model to voice_autoencoder.h5\n",
            "Epoch 11/100\n",
            "6400/6400 [==============================] - 3s 526us/step - loss: -174.5083 - acc: 0.2139 - val_loss: -178.2646 - val_acc: 0.2263\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.21188 to 0.22625, saving model to voice_autoencoder.h5\n",
            "Epoch 12/100\n",
            "6400/6400 [==============================] - 3s 538us/step - loss: -175.5629 - acc: 0.2248 - val_loss: -179.3433 - val_acc: 0.2475\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.22625 to 0.24750, saving model to voice_autoencoder.h5\n",
            "Epoch 13/100\n",
            "6400/6400 [==============================] - 3s 529us/step - loss: -177.0556 - acc: 0.2386 - val_loss: -179.8919 - val_acc: 0.2487\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.24750 to 0.24875, saving model to voice_autoencoder.h5\n",
            "Epoch 14/100\n",
            "6400/6400 [==============================] - 3s 534us/step - loss: -178.1596 - acc: 0.2408 - val_loss: -181.6937 - val_acc: 0.2706\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.24875 to 0.27063, saving model to voice_autoencoder.h5\n",
            "Epoch 15/100\n",
            "6400/6400 [==============================] - 4s 554us/step - loss: -178.9831 - acc: 0.2508 - val_loss: -182.4995 - val_acc: 0.2350\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.27063\n",
            "Epoch 16/100\n",
            "6400/6400 [==============================] - 4s 568us/step - loss: -179.9084 - acc: 0.2509 - val_loss: -183.3516 - val_acc: 0.2612\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.27063\n",
            "Epoch 17/100\n",
            "6400/6400 [==============================] - 4s 574us/step - loss: -180.8623 - acc: 0.2558 - val_loss: -183.8740 - val_acc: 0.2412\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.27063\n",
            "Epoch 18/100\n",
            "6400/6400 [==============================] - 3s 528us/step - loss: -181.3613 - acc: 0.2580 - val_loss: -184.9834 - val_acc: 0.2525\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.27063\n",
            "Epoch 19/100\n",
            "6400/6400 [==============================] - 3s 537us/step - loss: -181.8699 - acc: 0.2455 - val_loss: -185.2705 - val_acc: 0.2469\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.27063\n",
            "Epoch 20/100\n",
            "6400/6400 [==============================] - 3s 532us/step - loss: -182.8227 - acc: 0.2647 - val_loss: -184.5537 - val_acc: 0.2569\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.27063\n",
            "Epoch 21/100\n",
            "6400/6400 [==============================] - 3s 534us/step - loss: -183.0777 - acc: 0.2633 - val_loss: -186.3695 - val_acc: 0.2850\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.27063 to 0.28500, saving model to voice_autoencoder.h5\n",
            "Epoch 22/100\n",
            "6400/6400 [==============================] - 3s 539us/step - loss: -183.5944 - acc: 0.2652 - val_loss: -186.3662 - val_acc: 0.2675\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.28500\n",
            "Epoch 23/100\n",
            "6400/6400 [==============================] - 3s 531us/step - loss: -184.2855 - acc: 0.2753 - val_loss: -186.8072 - val_acc: 0.2812\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.28500\n",
            "Epoch 24/100\n",
            "6400/6400 [==============================] - 3s 530us/step - loss: -184.7438 - acc: 0.2808 - val_loss: -187.1873 - val_acc: 0.2437\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.28500\n",
            "Epoch 25/100\n",
            "6400/6400 [==============================] - 3s 528us/step - loss: -185.1021 - acc: 0.2792 - val_loss: -187.8821 - val_acc: 0.2737\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.28500\n",
            "Epoch 26/100\n",
            "6400/6400 [==============================] - 3s 532us/step - loss: -185.3764 - acc: 0.2839 - val_loss: -187.6726 - val_acc: 0.2669\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.28500\n",
            "Epoch 27/100\n",
            "6400/6400 [==============================] - 3s 542us/step - loss: -185.7640 - acc: 0.2755 - val_loss: -187.8116 - val_acc: 0.2756\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.28500\n",
            "Epoch 28/100\n",
            "6400/6400 [==============================] - 3s 535us/step - loss: -185.8289 - acc: 0.2820 - val_loss: -188.6189 - val_acc: 0.3081\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.28500 to 0.30812, saving model to voice_autoencoder.h5\n",
            "Epoch 29/100\n",
            "6400/6400 [==============================] - 3s 530us/step - loss: -186.4547 - acc: 0.2888 - val_loss: -188.7920 - val_acc: 0.2906\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.30812\n",
            "Epoch 30/100\n",
            "6400/6400 [==============================] - 3s 543us/step - loss: -186.6904 - acc: 0.2961 - val_loss: -189.1602 - val_acc: 0.2944\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.30812\n",
            "Epoch 31/100\n",
            "6400/6400 [==============================] - 3s 529us/step - loss: -186.9960 - acc: 0.2903 - val_loss: -189.1612 - val_acc: 0.2431\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.30812\n",
            "Epoch 32/100\n",
            "6400/6400 [==============================] - 3s 537us/step - loss: -187.1446 - acc: 0.2941 - val_loss: -189.0556 - val_acc: 0.2625\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.30812\n",
            "Epoch 33/100\n",
            "6400/6400 [==============================] - 3s 532us/step - loss: -187.1753 - acc: 0.2988 - val_loss: -189.8698 - val_acc: 0.2956\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.30812\n",
            "Epoch 34/100\n",
            "6400/6400 [==============================] - 3s 530us/step - loss: -187.8802 - acc: 0.3064 - val_loss: -189.7616 - val_acc: 0.2900\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.30812\n",
            "Epoch 35/100\n",
            "6400/6400 [==============================] - 3s 534us/step - loss: -187.9167 - acc: 0.3011 - val_loss: -190.1800 - val_acc: 0.2963\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.30812\n",
            "Epoch 36/100\n",
            "6400/6400 [==============================] - 3s 531us/step - loss: -188.2823 - acc: 0.2970 - val_loss: -190.1836 - val_acc: 0.2831\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.30812\n",
            "Epoch 37/100\n",
            "6400/6400 [==============================] - 3s 536us/step - loss: -188.2774 - acc: 0.2955 - val_loss: -190.2403 - val_acc: 0.2756\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.30812\n",
            "Epoch 38/100\n",
            "6400/6400 [==============================] - 3s 531us/step - loss: -188.3947 - acc: 0.2967 - val_loss: -190.5441 - val_acc: 0.2794\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.30812\n",
            "Epoch 39/100\n",
            "6400/6400 [==============================] - 3s 537us/step - loss: -188.6981 - acc: 0.2955 - val_loss: -190.7676 - val_acc: 0.2956\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.30812\n",
            "Epoch 40/100\n",
            "6400/6400 [==============================] - 3s 524us/step - loss: -188.8342 - acc: 0.3169 - val_loss: -191.1016 - val_acc: 0.3056\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.30812\n",
            "Epoch 41/100\n",
            "6400/6400 [==============================] - 3s 538us/step - loss: -189.1051 - acc: 0.3144 - val_loss: -191.0592 - val_acc: 0.2787\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.30812\n",
            "Epoch 42/100\n",
            "6400/6400 [==============================] - 3s 531us/step - loss: -188.8861 - acc: 0.3080 - val_loss: -191.1469 - val_acc: 0.3206\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.30812 to 0.32062, saving model to voice_autoencoder.h5\n",
            "Epoch 43/100\n",
            "6400/6400 [==============================] - 3s 518us/step - loss: -189.4691 - acc: 0.3150 - val_loss: -191.2174 - val_acc: 0.2812\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.32062\n",
            "Epoch 44/100\n",
            "6400/6400 [==============================] - 3s 538us/step - loss: -189.5160 - acc: 0.3181 - val_loss: -191.0845 - val_acc: 0.2794\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.32062\n",
            "Epoch 45/100\n",
            "6400/6400 [==============================] - 3s 533us/step - loss: -189.7445 - acc: 0.3025 - val_loss: -191.7254 - val_acc: 0.2812\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.32062\n",
            "Epoch 46/100\n",
            "6400/6400 [==============================] - 3s 526us/step - loss: -190.1431 - acc: 0.3156 - val_loss: -192.0516 - val_acc: 0.2975\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.32062\n",
            "Epoch 47/100\n",
            "6400/6400 [==============================] - 3s 531us/step - loss: -190.1488 - acc: 0.3144 - val_loss: -192.0418 - val_acc: 0.3019\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.32062\n",
            "Epoch 48/100\n",
            "6400/6400 [==============================] - 3s 533us/step - loss: -190.3943 - acc: 0.3117 - val_loss: -191.9085 - val_acc: 0.2950\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.32062\n",
            "Epoch 49/100\n",
            "6400/6400 [==============================] - 3s 532us/step - loss: -190.5091 - acc: 0.2984 - val_loss: -191.8553 - val_acc: 0.2938\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.32062\n",
            "Epoch 50/100\n",
            "6400/6400 [==============================] - 3s 536us/step - loss: -190.7578 - acc: 0.3106 - val_loss: -192.0558 - val_acc: 0.2900\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.32062\n",
            "Epoch 51/100\n",
            "6400/6400 [==============================] - 3s 530us/step - loss: -190.7929 - acc: 0.3172 - val_loss: -192.1427 - val_acc: 0.2838\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.32062\n",
            "Epoch 52/100\n",
            "6400/6400 [==============================] - 3s 523us/step - loss: -190.7316 - acc: 0.3166 - val_loss: -191.7663 - val_acc: 0.2969\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.32062\n",
            "Epoch 53/100\n",
            "6400/6400 [==============================] - 3s 531us/step - loss: -190.9365 - acc: 0.3184 - val_loss: -192.7736 - val_acc: 0.2925\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.32062\n",
            "Epoch 54/100\n",
            "6400/6400 [==============================] - 3s 534us/step - loss: -191.4070 - acc: 0.3244 - val_loss: -193.0959 - val_acc: 0.3187\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.32062\n",
            "Epoch 55/100\n",
            "6400/6400 [==============================] - 3s 535us/step - loss: -191.3075 - acc: 0.3180 - val_loss: -192.5307 - val_acc: 0.3119\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.32062\n",
            "Epoch 56/100\n",
            "6400/6400 [==============================] - 3s 535us/step - loss: -191.4270 - acc: 0.3173 - val_loss: -192.7569 - val_acc: 0.2844\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.32062\n",
            "Epoch 57/100\n",
            "6400/6400 [==============================] - 3s 533us/step - loss: -191.6348 - acc: 0.3145 - val_loss: -192.9907 - val_acc: 0.3200\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.32062\n",
            "Epoch 58/100\n",
            "6400/6400 [==============================] - 3s 532us/step - loss: -191.8613 - acc: 0.3242 - val_loss: -193.1307 - val_acc: 0.3038\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.32062\n",
            "Epoch 59/100\n",
            "6400/6400 [==============================] - 3s 534us/step - loss: -191.5852 - acc: 0.3259 - val_loss: -192.6148 - val_acc: 0.3100\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.32062\n",
            "Epoch 60/100\n",
            "6400/6400 [==============================] - 3s 540us/step - loss: -191.9843 - acc: 0.3398 - val_loss: -193.4195 - val_acc: 0.3019\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.32062\n",
            "Epoch 61/100\n",
            "6400/6400 [==============================] - 3s 534us/step - loss: -192.1165 - acc: 0.3331 - val_loss: -193.1107 - val_acc: 0.3125\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.32062\n",
            "Epoch 62/100\n",
            "6400/6400 [==============================] - 3s 534us/step - loss: -191.8732 - acc: 0.3181 - val_loss: -193.2602 - val_acc: 0.3175\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.32062\n",
            "Epoch 63/100\n",
            "6400/6400 [==============================] - 3s 536us/step - loss: -192.1927 - acc: 0.3233 - val_loss: -193.4999 - val_acc: 0.3281\n",
            "\n",
            "Epoch 00063: val_acc improved from 0.32062 to 0.32812, saving model to voice_autoencoder.h5\n",
            "Epoch 64/100\n",
            "6400/6400 [==============================] - 3s 527us/step - loss: -192.3407 - acc: 0.3306 - val_loss: -193.2833 - val_acc: 0.3231\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.32812\n",
            "Epoch 65/100\n",
            "6400/6400 [==============================] - 3s 531us/step - loss: -192.3618 - acc: 0.3237 - val_loss: -193.6794 - val_acc: 0.3312\n",
            "\n",
            "Epoch 00065: val_acc improved from 0.32812 to 0.33125, saving model to voice_autoencoder.h5\n",
            "Epoch 66/100\n",
            "6400/6400 [==============================] - 3s 536us/step - loss: -192.5801 - acc: 0.3364 - val_loss: -193.7321 - val_acc: 0.3131\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.33125\n",
            "Epoch 67/100\n",
            "6400/6400 [==============================] - 3s 542us/step - loss: -192.5832 - acc: 0.3278 - val_loss: -193.6116 - val_acc: 0.3119\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.33125\n",
            "Epoch 68/100\n",
            "6400/6400 [==============================] - 3s 533us/step - loss: -192.6049 - acc: 0.3330 - val_loss: -193.2487 - val_acc: 0.3231\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.33125\n",
            "Epoch 69/100\n",
            "6400/6400 [==============================] - 4s 564us/step - loss: -192.5253 - acc: 0.3222 - val_loss: -193.6236 - val_acc: 0.3013\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.33125\n",
            "Epoch 70/100\n",
            "6400/6400 [==============================] - 4s 555us/step - loss: -192.6772 - acc: 0.3319 - val_loss: -193.8370 - val_acc: 0.3137\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.33125\n",
            "Epoch 71/100\n",
            "6400/6400 [==============================] - 3s 525us/step - loss: -192.8999 - acc: 0.3259 - val_loss: -193.9081 - val_acc: 0.3275\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.33125\n",
            "Epoch 72/100\n",
            "6400/6400 [==============================] - 3s 535us/step - loss: -193.0466 - acc: 0.3425 - val_loss: -193.9657 - val_acc: 0.3262\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.33125\n",
            "Epoch 73/100\n",
            "6400/6400 [==============================] - 3s 528us/step - loss: -192.8489 - acc: 0.3398 - val_loss: -193.8905 - val_acc: 0.3194\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.33125\n",
            "Epoch 74/100\n",
            "6400/6400 [==============================] - 3s 526us/step - loss: -192.8588 - acc: 0.3389 - val_loss: -194.0137 - val_acc: 0.3156\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.33125\n",
            "Epoch 75/100\n",
            "6400/6400 [==============================] - 3s 530us/step - loss: -193.1021 - acc: 0.3273 - val_loss: -193.8428 - val_acc: 0.3212\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.33125\n",
            "Epoch 76/100\n",
            "6400/6400 [==============================] - 3s 526us/step - loss: -193.3798 - acc: 0.3398 - val_loss: -193.9879 - val_acc: 0.3075\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.33125\n",
            "Epoch 77/100\n",
            "6400/6400 [==============================] - 3s 521us/step - loss: -193.2827 - acc: 0.3294 - val_loss: -194.0120 - val_acc: 0.3137\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.33125\n",
            "Epoch 78/100\n",
            "6400/6400 [==============================] - 3s 541us/step - loss: -193.4804 - acc: 0.3414 - val_loss: -194.0170 - val_acc: 0.3294\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.33125\n",
            "Epoch 79/100\n",
            "6400/6400 [==============================] - 3s 531us/step - loss: -193.3735 - acc: 0.3473 - val_loss: -194.0313 - val_acc: 0.3306\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.33125\n",
            "Epoch 80/100\n",
            "6400/6400 [==============================] - 3s 524us/step - loss: -192.8814 - acc: 0.3291 - val_loss: -193.7659 - val_acc: 0.3006\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.33125\n",
            "Epoch 81/100\n",
            "6400/6400 [==============================] - 3s 533us/step - loss: -193.0177 - acc: 0.3420 - val_loss: -194.4429 - val_acc: 0.3106\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.33125\n",
            "Epoch 82/100\n",
            "6400/6400 [==============================] - 3s 528us/step - loss: -193.5263 - acc: 0.3431 - val_loss: -194.3098 - val_acc: 0.3381\n",
            "\n",
            "Epoch 00082: val_acc improved from 0.33125 to 0.33813, saving model to voice_autoencoder.h5\n",
            "Epoch 83/100\n",
            "6400/6400 [==============================] - 3s 527us/step - loss: -193.5950 - acc: 0.3422 - val_loss: -194.2940 - val_acc: 0.3244\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.33813\n",
            "Epoch 84/100\n",
            "6400/6400 [==============================] - 3s 529us/step - loss: -193.7161 - acc: 0.3419 - val_loss: -194.5222 - val_acc: 0.3425\n",
            "\n",
            "Epoch 00084: val_acc improved from 0.33813 to 0.34250, saving model to voice_autoencoder.h5\n",
            "Epoch 85/100\n",
            "6400/6400 [==============================] - 3s 536us/step - loss: -193.6097 - acc: 0.3362 - val_loss: -194.2002 - val_acc: 0.3456\n",
            "\n",
            "Epoch 00085: val_acc improved from 0.34250 to 0.34563, saving model to voice_autoencoder.h5\n",
            "Epoch 86/100\n",
            "6400/6400 [==============================] - 3s 530us/step - loss: -193.7502 - acc: 0.3425 - val_loss: -194.4974 - val_acc: 0.3419\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.34563\n",
            "Epoch 87/100\n",
            "6400/6400 [==============================] - 3s 526us/step - loss: -193.3722 - acc: 0.3311 - val_loss: -194.0255 - val_acc: 0.3212\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.34563\n",
            "Epoch 88/100\n",
            "6400/6400 [==============================] - 3s 538us/step - loss: -193.5668 - acc: 0.3339 - val_loss: -194.1177 - val_acc: 0.3569\n",
            "\n",
            "Epoch 00088: val_acc improved from 0.34563 to 0.35687, saving model to voice_autoencoder.h5\n",
            "Epoch 89/100\n",
            "6400/6400 [==============================] - 3s 537us/step - loss: -193.8815 - acc: 0.3425 - val_loss: -194.1267 - val_acc: 0.3262\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.35687\n",
            "Epoch 90/100\n",
            "6400/6400 [==============================] - 3s 540us/step - loss: -193.8731 - acc: 0.3416 - val_loss: -194.7536 - val_acc: 0.3256\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.35687\n",
            "Epoch 91/100\n",
            "6400/6400 [==============================] - 3s 536us/step - loss: -193.8136 - acc: 0.3472 - val_loss: -194.5236 - val_acc: 0.3319\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.35687\n",
            "Epoch 92/100\n",
            "6400/6400 [==============================] - 3s 527us/step - loss: -193.9928 - acc: 0.3394 - val_loss: -194.8501 - val_acc: 0.3275\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.35687\n",
            "Epoch 93/100\n",
            "6400/6400 [==============================] - 3s 527us/step - loss: -194.3702 - acc: 0.3466 - val_loss: -194.8892 - val_acc: 0.3500\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.35687\n",
            "Epoch 94/100\n",
            "6400/6400 [==============================] - 3s 527us/step - loss: -194.3163 - acc: 0.3589 - val_loss: -194.8257 - val_acc: 0.3438\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.35687\n",
            "Epoch 95/100\n",
            "6400/6400 [==============================] - 3s 537us/step - loss: -193.6549 - acc: 0.3323 - val_loss: -194.5819 - val_acc: 0.3425\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.35687\n",
            "Epoch 96/100\n",
            "6400/6400 [==============================] - 3s 532us/step - loss: -194.1935 - acc: 0.3416 - val_loss: -194.5069 - val_acc: 0.3656\n",
            "\n",
            "Epoch 00096: val_acc improved from 0.35687 to 0.36562, saving model to voice_autoencoder.h5\n",
            "Epoch 97/100\n",
            "6400/6400 [==============================] - 3s 528us/step - loss: -194.3215 - acc: 0.3441 - val_loss: -194.5163 - val_acc: 0.3344\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.36562\n",
            "Epoch 98/100\n",
            "6400/6400 [==============================] - 3s 531us/step - loss: -194.1510 - acc: 0.3463 - val_loss: -194.8911 - val_acc: 0.3713\n",
            "\n",
            "Epoch 00098: val_acc improved from 0.36562 to 0.37125, saving model to voice_autoencoder.h5\n",
            "Epoch 99/100\n",
            "6400/6400 [==============================] - 3s 524us/step - loss: -194.6035 - acc: 0.3500 - val_loss: -194.9280 - val_acc: 0.3312\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.37125\n",
            "Epoch 100/100\n",
            "6400/6400 [==============================] - 3s 515us/step - loss: -194.4595 - acc: 0.3452 - val_loss: -194.9923 - val_acc: 0.3463\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.37125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CVSQnib_L9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "2141ca97-9310-447b-cd82-9731a4649aa8"
      },
      "source": [
        "loss = autoencoder_train.history['loss']\n",
        "val_loss = autoencoder_train.history['val_loss']\n",
        "epochs = range(100)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label = 'Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n",
        "plt.title('Training and Validation Loss for Autoencoders on MFCCs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIwxJuAsEBhjTMBZIDDGmID7f554lc7XsspmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9VRhB6oApse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.save_weights('Autoencoder_Voices_Weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_TEsDbuA3Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = Input(shape = (40, ))\n",
        "x = Dense(128, activation = 'relu')(input)\n",
        "x = Dense(128, activation = 'relu')(x)\n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "encoded = Dense(32, activation = 'relu')(x)\n",
        "x = Dense(128, activation = 'relu')(encoded)\n",
        "output = Dense(100, activation = 'softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni0ReOKVBIlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_model = Model(input, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx8kyuSBBMpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "687d6ca0-1418-4a11-b055-43249ef1fae4"
      },
      "source": [
        "len(full_model.layers)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1LIIhkzBO0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for l1, l2 in zip(full_model.layers[:6], autoencoder.layers[0:6]):\n",
        "  l1.set_weights(l2.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EJIMro_BVed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "bfc96d8d-8e2a-42cd-bf6f-8f06e2e20dcd"
      },
      "source": [
        "autoencoder.get_weights()[0][1]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.05387349, -0.10567961,  0.19412678,  0.17528418,  0.25584242,\n",
              "       -0.15974623,  0.3653098 , -0.66731364, -0.21035647, -0.16649148,\n",
              "       -0.0692225 , -0.040491  ,  0.19600216, -0.35123584, -0.5212695 ,\n",
              "       -0.45420045, -0.05359562,  0.22080202,  0.11263556,  0.11165377,\n",
              "        0.1522395 ,  0.74657553,  0.20379923,  0.1711179 , -0.14913252,\n",
              "        0.05878667, -0.30182847, -0.14830917,  0.2060685 ,  0.17622708,\n",
              "        0.19013682, -0.10642849,  0.06285158, -0.48234412, -0.04240697,\n",
              "        0.22406282,  0.03625853, -0.22430946, -0.27700734, -0.06248192,\n",
              "       -0.03643917, -0.37369007,  0.12959088, -0.00550769,  0.4069404 ,\n",
              "       -0.76144636,  0.14754324,  0.06707559, -0.273207  ,  0.22935112,\n",
              "        0.13974652, -0.01262413, -0.07659116,  0.03220008, -0.35661426,\n",
              "       -0.31055135,  0.00755485,  0.07798854, -0.24147794, -0.18338472,\n",
              "        0.1364172 , -0.0562776 ,  0.14168973, -0.13718778,  0.13327935,\n",
              "       -0.32742736, -0.06032571, -0.06628612,  0.0475603 , -0.19429983,\n",
              "        0.34744295,  0.1741643 ,  0.17487012, -0.08662941,  0.36749148,\n",
              "       -0.0956079 ,  0.13405424,  0.28210017, -0.03779141,  0.0412449 ,\n",
              "        0.11835308, -0.02591261, -0.0018047 , -0.11861268, -0.10926878,\n",
              "        0.05006341, -0.17741454, -0.0480874 ,  0.25084642, -0.21726175,\n",
              "       -0.07072257, -0.22798795,  0.16846883, -0.51759744, -0.17714742,\n",
              "        0.35206077, -0.17040744,  0.14840294,  0.03181427,  0.06831217,\n",
              "        0.10835455, -0.1177272 , -0.11979278, -0.40929645, -0.08042813,\n",
              "        0.11843964, -0.01982791, -0.01846399,  0.43052098,  0.00728049,\n",
              "        0.20005678,  0.0128846 , -0.08214093,  0.27385873,  0.11164593,\n",
              "        0.5083549 , -0.15967405,  0.02584524,  0.02006115, -0.23978233,\n",
              "       -0.10163394, -0.26493606,  0.05345678,  0.0460225 ,  0.65370554,\n",
              "       -0.07441781,  0.4651257 ,  0.0817588 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaXQB0wnBXvk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "e49c6540-9653-4250-b543-72713eca625a"
      },
      "source": [
        "full_model.get_weights()[0][1]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.05387349, -0.10567961,  0.19412678,  0.17528418,  0.25584242,\n",
              "       -0.15974623,  0.3653098 , -0.66731364, -0.21035647, -0.16649148,\n",
              "       -0.0692225 , -0.040491  ,  0.19600216, -0.35123584, -0.5212695 ,\n",
              "       -0.45420045, -0.05359562,  0.22080202,  0.11263556,  0.11165377,\n",
              "        0.1522395 ,  0.74657553,  0.20379923,  0.1711179 , -0.14913252,\n",
              "        0.05878667, -0.30182847, -0.14830917,  0.2060685 ,  0.17622708,\n",
              "        0.19013682, -0.10642849,  0.06285158, -0.48234412, -0.04240697,\n",
              "        0.22406282,  0.03625853, -0.22430946, -0.27700734, -0.06248192,\n",
              "       -0.03643917, -0.37369007,  0.12959088, -0.00550769,  0.4069404 ,\n",
              "       -0.76144636,  0.14754324,  0.06707559, -0.273207  ,  0.22935112,\n",
              "        0.13974652, -0.01262413, -0.07659116,  0.03220008, -0.35661426,\n",
              "       -0.31055135,  0.00755485,  0.07798854, -0.24147794, -0.18338472,\n",
              "        0.1364172 , -0.0562776 ,  0.14168973, -0.13718778,  0.13327935,\n",
              "       -0.32742736, -0.06032571, -0.06628612,  0.0475603 , -0.19429983,\n",
              "        0.34744295,  0.1741643 ,  0.17487012, -0.08662941,  0.36749148,\n",
              "       -0.0956079 ,  0.13405424,  0.28210017, -0.03779141,  0.0412449 ,\n",
              "        0.11835308, -0.02591261, -0.0018047 , -0.11861268, -0.10926878,\n",
              "        0.05006341, -0.17741454, -0.0480874 ,  0.25084642, -0.21726175,\n",
              "       -0.07072257, -0.22798795,  0.16846883, -0.51759744, -0.17714742,\n",
              "        0.35206077, -0.17040744,  0.14840294,  0.03181427,  0.06831217,\n",
              "        0.10835455, -0.1177272 , -0.11979278, -0.40929645, -0.08042813,\n",
              "        0.11843964, -0.01982791, -0.01846399,  0.43052098,  0.00728049,\n",
              "        0.20005678,  0.0128846 , -0.08214093,  0.27385873,  0.11164593,\n",
              "        0.5083549 , -0.15967405,  0.02584524,  0.02006115, -0.23978233,\n",
              "       -0.10163394, -0.26493606,  0.05345678,  0.0460225 ,  0.65370554,\n",
              "       -0.07441781,  0.4651257 ,  0.0817588 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qwFmol5BbCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in full_model.layers[0:6]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-kIgwlrBgdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omUm54poBjXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "84e5691e-8694-4deb-d6e8-cafc760cb8c8"
      },
      "source": [
        "full_model.summary()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               5248      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               4224      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 53,380\n",
            "Trainable params: 17,124\n",
            "Non-trainable params: 36,256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y-23L17BlSe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ecd5733-ef20-456d-9975-10879d2bda00"
      },
      "source": [
        "filepath = 'pretrained_voice_best_weights.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
        "callbacks_list = [checkpoint]\n",
        "pretrained_classifier_train = full_model.fit(X_train, y_train, epochs = 100, batch_size = 16, verbose = 1, callbacks = callbacks_list, validation_data = [X_val, y_val])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/100\n",
            "6400/6400 [==============================] - 2s 359us/step - loss: 1.8114 - acc: 0.6584 - val_loss: 0.6372 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.89125, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 2/100\n",
            "6400/6400 [==============================] - 2s 307us/step - loss: 0.4794 - acc: 0.9147 - val_loss: 0.4460 - val_acc: 0.9231\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.89125 to 0.92312, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 3/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.3415 - acc: 0.9381 - val_loss: 0.3611 - val_acc: 0.9369\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.92312 to 0.93688, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 4/100\n",
            "6400/6400 [==============================] - 2s 311us/step - loss: 0.2845 - acc: 0.9531 - val_loss: 0.3332 - val_acc: 0.9400\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.93688 to 0.94000, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 5/100\n",
            "6400/6400 [==============================] - 2s 302us/step - loss: 0.2491 - acc: 0.9586 - val_loss: 0.3231 - val_acc: 0.9394\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.94000\n",
            "Epoch 6/100\n",
            "6400/6400 [==============================] - 2s 309us/step - loss: 0.2264 - acc: 0.9631 - val_loss: 0.3262 - val_acc: 0.9344\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.94000\n",
            "Epoch 7/100\n",
            "6400/6400 [==============================] - 2s 319us/step - loss: 0.2040 - acc: 0.9702 - val_loss: 0.3231 - val_acc: 0.9400\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.94000\n",
            "Epoch 8/100\n",
            "6400/6400 [==============================] - 2s 319us/step - loss: 0.2022 - acc: 0.9678 - val_loss: 0.3047 - val_acc: 0.9487\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.94000 to 0.94875, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 9/100\n",
            "6400/6400 [==============================] - 2s 330us/step - loss: 0.1773 - acc: 0.9723 - val_loss: 0.2961 - val_acc: 0.9500\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.94875 to 0.95000, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 10/100\n",
            "6400/6400 [==============================] - 2s 328us/step - loss: 0.1722 - acc: 0.9750 - val_loss: 0.3090 - val_acc: 0.9481\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.95000\n",
            "Epoch 11/100\n",
            "6400/6400 [==============================] - 2s 328us/step - loss: 0.1755 - acc: 0.9734 - val_loss: 0.2931 - val_acc: 0.9525\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.95000 to 0.95250, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 12/100\n",
            "6400/6400 [==============================] - 2s 334us/step - loss: 0.1543 - acc: 0.9798 - val_loss: 0.2838 - val_acc: 0.9487\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.95250\n",
            "Epoch 13/100\n",
            "6400/6400 [==============================] - 2s 316us/step - loss: 0.1555 - acc: 0.9764 - val_loss: 0.2921 - val_acc: 0.9525\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.95250\n",
            "Epoch 14/100\n",
            "6400/6400 [==============================] - 2s 313us/step - loss: 0.1437 - acc: 0.9836 - val_loss: 0.2964 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.95250 to 0.95437, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 15/100\n",
            "6400/6400 [==============================] - 2s 311us/step - loss: 0.1416 - acc: 0.9817 - val_loss: 0.3424 - val_acc: 0.9425\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.95437\n",
            "Epoch 16/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.1488 - acc: 0.9797 - val_loss: 0.3070 - val_acc: 0.9537\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.95437\n",
            "Epoch 17/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.1369 - acc: 0.9819 - val_loss: 0.3260 - val_acc: 0.9425\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.95437\n",
            "Epoch 18/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.1329 - acc: 0.9844 - val_loss: 0.3209 - val_acc: 0.9487\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.95437\n",
            "Epoch 19/100\n",
            "6400/6400 [==============================] - 2s 320us/step - loss: 0.1256 - acc: 0.9864 - val_loss: 0.3132 - val_acc: 0.9494\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.95437\n",
            "Epoch 20/100\n",
            "6400/6400 [==============================] - 2s 310us/step - loss: 0.1288 - acc: 0.9867 - val_loss: 0.3130 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.95437 to 0.95937, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 21/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.1265 - acc: 0.9842 - val_loss: 0.3040 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.95937\n",
            "Epoch 22/100\n",
            "6400/6400 [==============================] - 2s 314us/step - loss: 0.1328 - acc: 0.9831 - val_loss: 0.3402 - val_acc: 0.9463\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.95937\n",
            "Epoch 23/100\n",
            "6400/6400 [==============================] - 2s 304us/step - loss: 0.1375 - acc: 0.9827 - val_loss: 0.3431 - val_acc: 0.9513\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.95937\n",
            "Epoch 24/100\n",
            "6400/6400 [==============================] - 2s 305us/step - loss: 0.1277 - acc: 0.9844 - val_loss: 0.3121 - val_acc: 0.9587\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.95937\n",
            "Epoch 25/100\n",
            "6400/6400 [==============================] - 2s 316us/step - loss: 0.1175 - acc: 0.9891 - val_loss: 0.3085 - val_acc: 0.9575\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.95937\n",
            "Epoch 26/100\n",
            "6400/6400 [==============================] - 2s 313us/step - loss: 0.1125 - acc: 0.9898 - val_loss: 0.3077 - val_acc: 0.9550\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.95937\n",
            "Epoch 27/100\n",
            "6400/6400 [==============================] - 2s 314us/step - loss: 0.1246 - acc: 0.9869 - val_loss: 0.3681 - val_acc: 0.9463\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.95937\n",
            "Epoch 28/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.1220 - acc: 0.9869 - val_loss: 0.3464 - val_acc: 0.9537\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.95937\n",
            "Epoch 29/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.1121 - acc: 0.9902 - val_loss: 0.3017 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.95937\n",
            "Epoch 30/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.1106 - acc: 0.9894 - val_loss: 0.3257 - val_acc: 0.9563\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.95937\n",
            "Epoch 31/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.1232 - acc: 0.9855 - val_loss: 0.3300 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.95937\n",
            "Epoch 32/100\n",
            "6400/6400 [==============================] - 2s 307us/step - loss: 0.1102 - acc: 0.9897 - val_loss: 0.3253 - val_acc: 0.9575\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.95937\n",
            "Epoch 33/100\n",
            "6400/6400 [==============================] - 2s 315us/step - loss: 0.1143 - acc: 0.9895 - val_loss: 0.3249 - val_acc: 0.9556\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.95937\n",
            "Epoch 34/100\n",
            "6400/6400 [==============================] - 2s 314us/step - loss: 0.1109 - acc: 0.9897 - val_loss: 0.3552 - val_acc: 0.9494\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.95937\n",
            "Epoch 35/100\n",
            "6400/6400 [==============================] - 2s 318us/step - loss: 0.1097 - acc: 0.9898 - val_loss: 0.3106 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.95937\n",
            "Epoch 36/100\n",
            "6400/6400 [==============================] - 2s 319us/step - loss: 0.1044 - acc: 0.9917 - val_loss: 0.3276 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.95937\n",
            "Epoch 37/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.1143 - acc: 0.9884 - val_loss: 0.3343 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.95937\n",
            "Epoch 38/100\n",
            "6400/6400 [==============================] - 2s 315us/step - loss: 0.1156 - acc: 0.9880 - val_loss: 0.3444 - val_acc: 0.9519\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.95937\n",
            "Epoch 39/100\n",
            "6400/6400 [==============================] - 2s 303us/step - loss: 0.1166 - acc: 0.9878 - val_loss: 0.3475 - val_acc: 0.9531\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.95937\n",
            "Epoch 40/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.1111 - acc: 0.9902 - val_loss: 0.3516 - val_acc: 0.9513\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.95937\n",
            "Epoch 41/100\n",
            "6400/6400 [==============================] - 2s 311us/step - loss: 0.1124 - acc: 0.9898 - val_loss: 0.3316 - val_acc: 0.9525\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.95937\n",
            "Epoch 42/100\n",
            "6400/6400 [==============================] - 2s 311us/step - loss: 0.1065 - acc: 0.9912 - val_loss: 0.3318 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.95937\n",
            "Epoch 43/100\n",
            "6400/6400 [==============================] - 2s 314us/step - loss: 0.1013 - acc: 0.9925 - val_loss: 0.3336 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.95937\n",
            "Epoch 44/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.1004 - acc: 0.9927 - val_loss: 0.3340 - val_acc: 0.9600\n",
            "\n",
            "Epoch 00044: val_acc improved from 0.95937 to 0.96000, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 45/100\n",
            "6400/6400 [==============================] - 2s 307us/step - loss: 0.1035 - acc: 0.9912 - val_loss: 0.3477 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.96000\n",
            "Epoch 46/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.1022 - acc: 0.9920 - val_loss: 0.3585 - val_acc: 0.9575\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.96000\n",
            "Epoch 47/100\n",
            "6400/6400 [==============================] - 2s 313us/step - loss: 0.1187 - acc: 0.9877 - val_loss: 0.4064 - val_acc: 0.9400\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.96000\n",
            "Epoch 48/100\n",
            "6400/6400 [==============================] - 2s 315us/step - loss: 0.1196 - acc: 0.9862 - val_loss: 0.3867 - val_acc: 0.9513\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.96000\n",
            "Epoch 49/100\n",
            "6400/6400 [==============================] - 2s 316us/step - loss: 0.1097 - acc: 0.9898 - val_loss: 0.3805 - val_acc: 0.9513\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.96000\n",
            "Epoch 50/100\n",
            "6400/6400 [==============================] - 2s 317us/step - loss: 0.1082 - acc: 0.9906 - val_loss: 0.3542 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.96000\n",
            "Epoch 51/100\n",
            "6400/6400 [==============================] - 2s 320us/step - loss: 0.0989 - acc: 0.9933 - val_loss: 0.3506 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.96000\n",
            "Epoch 52/100\n",
            "6400/6400 [==============================] - 2s 306us/step - loss: 0.1002 - acc: 0.9930 - val_loss: 0.3582 - val_acc: 0.9563\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.96000\n",
            "Epoch 53/100\n",
            "6400/6400 [==============================] - 2s 310us/step - loss: 0.1041 - acc: 0.9911 - val_loss: 0.3629 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.96000\n",
            "Epoch 54/100\n",
            "6400/6400 [==============================] - 2s 309us/step - loss: 0.1002 - acc: 0.9925 - val_loss: 0.3535 - val_acc: 0.9569\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.96000\n",
            "Epoch 55/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.1086 - acc: 0.9903 - val_loss: 0.3930 - val_acc: 0.9513\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.96000\n",
            "Epoch 56/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.1121 - acc: 0.9903 - val_loss: 0.3568 - val_acc: 0.9550\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.96000\n",
            "Epoch 57/100\n",
            "6400/6400 [==============================] - 2s 310us/step - loss: 0.1157 - acc: 0.9894 - val_loss: 0.3505 - val_acc: 0.9556\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.96000\n",
            "Epoch 58/100\n",
            "6400/6400 [==============================] - 2s 310us/step - loss: 0.1031 - acc: 0.9912 - val_loss: 0.3773 - val_acc: 0.9494\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.96000\n",
            "Epoch 59/100\n",
            "6400/6400 [==============================] - 2s 315us/step - loss: 0.1001 - acc: 0.9922 - val_loss: 0.3515 - val_acc: 0.9563\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.96000\n",
            "Epoch 60/100\n",
            "6400/6400 [==============================] - 2s 311us/step - loss: 0.1029 - acc: 0.9906 - val_loss: 0.3628 - val_acc: 0.9519\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.96000\n",
            "Epoch 61/100\n",
            "6400/6400 [==============================] - 2s 306us/step - loss: 0.1007 - acc: 0.9922 - val_loss: 0.3630 - val_acc: 0.9575\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.96000\n",
            "Epoch 62/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.0978 - acc: 0.9931 - val_loss: 0.3570 - val_acc: 0.9550\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.96000\n",
            "Epoch 63/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.0972 - acc: 0.9930 - val_loss: 0.3703 - val_acc: 0.9550\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.96000\n",
            "Epoch 64/100\n",
            "6400/6400 [==============================] - 2s 314us/step - loss: 0.1069 - acc: 0.9905 - val_loss: 0.3626 - val_acc: 0.9525\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.96000\n",
            "Epoch 65/100\n",
            "6400/6400 [==============================] - 2s 306us/step - loss: 0.1085 - acc: 0.9891 - val_loss: 0.3802 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.96000\n",
            "Epoch 66/100\n",
            "6400/6400 [==============================] - 2s 313us/step - loss: 0.1013 - acc: 0.9919 - val_loss: 0.3753 - val_acc: 0.9550\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.96000\n",
            "Epoch 67/100\n",
            "6400/6400 [==============================] - 2s 309us/step - loss: 0.1010 - acc: 0.9923 - val_loss: 0.3792 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.96000\n",
            "Epoch 68/100\n",
            "6400/6400 [==============================] - 2s 318us/step - loss: 0.1009 - acc: 0.9927 - val_loss: 0.3755 - val_acc: 0.9606\n",
            "\n",
            "Epoch 00068: val_acc improved from 0.96000 to 0.96062, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 69/100\n",
            "6400/6400 [==============================] - 2s 307us/step - loss: 0.0959 - acc: 0.9934 - val_loss: 0.3625 - val_acc: 0.9606\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.96062\n",
            "Epoch 70/100\n",
            "6400/6400 [==============================] - 2s 315us/step - loss: 0.0963 - acc: 0.9930 - val_loss: 0.3733 - val_acc: 0.9569\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.96062\n",
            "Epoch 71/100\n",
            "6400/6400 [==============================] - 2s 317us/step - loss: 0.1052 - acc: 0.9914 - val_loss: 0.3884 - val_acc: 0.9525\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.96062\n",
            "Epoch 72/100\n",
            "6400/6400 [==============================] - 2s 313us/step - loss: 0.1271 - acc: 0.9870 - val_loss: 0.3811 - val_acc: 0.9487\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.96062\n",
            "Epoch 73/100\n",
            "6400/6400 [==============================] - 2s 308us/step - loss: 0.1016 - acc: 0.9920 - val_loss: 0.3620 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.96062\n",
            "Epoch 74/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.0969 - acc: 0.9933 - val_loss: 0.3776 - val_acc: 0.9569\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.96062\n",
            "Epoch 75/100\n",
            "6400/6400 [==============================] - 2s 322us/step - loss: 0.0984 - acc: 0.9928 - val_loss: 0.3780 - val_acc: 0.9550\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.96062\n",
            "Epoch 76/100\n",
            "6400/6400 [==============================] - 2s 307us/step - loss: 0.1002 - acc: 0.9923 - val_loss: 0.3905 - val_acc: 0.9587\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.96062\n",
            "Epoch 77/100\n",
            "6400/6400 [==============================] - 2s 311us/step - loss: 0.0951 - acc: 0.9937 - val_loss: 0.3815 - val_acc: 0.9600\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.96062\n",
            "Epoch 78/100\n",
            "6400/6400 [==============================] - 2s 310us/step - loss: 0.0950 - acc: 0.9939 - val_loss: 0.3833 - val_acc: 0.9587\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.96062\n",
            "Epoch 79/100\n",
            "6400/6400 [==============================] - 2s 320us/step - loss: 0.0988 - acc: 0.9933 - val_loss: 0.3811 - val_acc: 0.9613\n",
            "\n",
            "Epoch 00079: val_acc improved from 0.96062 to 0.96125, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 80/100\n",
            "6400/6400 [==============================] - 2s 316us/step - loss: 0.0954 - acc: 0.9936 - val_loss: 0.3806 - val_acc: 0.9563\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.96125\n",
            "Epoch 81/100\n",
            "6400/6400 [==============================] - 2s 313us/step - loss: 0.1044 - acc: 0.9914 - val_loss: 0.4023 - val_acc: 0.9513\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.96125\n",
            "Epoch 82/100\n",
            "6400/6400 [==============================] - 2s 311us/step - loss: 0.1131 - acc: 0.9891 - val_loss: 0.4310 - val_acc: 0.9425\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.96125\n",
            "Epoch 83/100\n",
            "6400/6400 [==============================] - 2s 321us/step - loss: 0.1166 - acc: 0.9895 - val_loss: 0.3634 - val_acc: 0.9587\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.96125\n",
            "Epoch 84/100\n",
            "6400/6400 [==============================] - 2s 310us/step - loss: 0.0989 - acc: 0.9925 - val_loss: 0.3744 - val_acc: 0.9606\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.96125\n",
            "Epoch 85/100\n",
            "6400/6400 [==============================] - 2s 307us/step - loss: 0.0960 - acc: 0.9934 - val_loss: 0.3751 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.96125\n",
            "Epoch 86/100\n",
            "6400/6400 [==============================] - 2s 309us/step - loss: 0.0981 - acc: 0.9930 - val_loss: 0.3807 - val_acc: 0.9619\n",
            "\n",
            "Epoch 00086: val_acc improved from 0.96125 to 0.96188, saving model to pretrained_voice_best_weights.h5\n",
            "Epoch 87/100\n",
            "6400/6400 [==============================] - 2s 304us/step - loss: 0.0954 - acc: 0.9936 - val_loss: 0.3792 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.96188\n",
            "Epoch 88/100\n",
            "6400/6400 [==============================] - 2s 316us/step - loss: 0.0979 - acc: 0.9931 - val_loss: 0.3697 - val_acc: 0.9619\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.96188\n",
            "Epoch 89/100\n",
            "6400/6400 [==============================] - 2s 309us/step - loss: 0.0975 - acc: 0.9927 - val_loss: 0.3964 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.96188\n",
            "Epoch 90/100\n",
            "6400/6400 [==============================] - 2s 312us/step - loss: 0.0973 - acc: 0.9930 - val_loss: 0.3993 - val_acc: 0.9500\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.96188\n",
            "Epoch 91/100\n",
            "6400/6400 [==============================] - 2s 315us/step - loss: 0.1045 - acc: 0.9902 - val_loss: 0.4220 - val_acc: 0.9556\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.96188\n",
            "Epoch 92/100\n",
            "6400/6400 [==============================] - 2s 307us/step - loss: 0.1025 - acc: 0.9917 - val_loss: 0.3749 - val_acc: 0.9575\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.96188\n",
            "Epoch 93/100\n",
            "6400/6400 [==============================] - 2s 310us/step - loss: 0.1032 - acc: 0.9911 - val_loss: 0.4076 - val_acc: 0.9550\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.96188\n",
            "Epoch 94/100\n",
            "6400/6400 [==============================] - 2s 309us/step - loss: 0.1016 - acc: 0.9925 - val_loss: 0.3655 - val_acc: 0.9556\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.96188\n",
            "Epoch 95/100\n",
            "6400/6400 [==============================] - 2s 313us/step - loss: 0.1023 - acc: 0.9919 - val_loss: 0.4207 - val_acc: 0.9506\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.96188\n",
            "Epoch 96/100\n",
            "6400/6400 [==============================] - 2s 320us/step - loss: 0.1051 - acc: 0.9916 - val_loss: 0.3722 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.96188\n",
            "Epoch 97/100\n",
            "6400/6400 [==============================] - 2s 330us/step - loss: 0.0974 - acc: 0.9930 - val_loss: 0.3733 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.96188\n",
            "Epoch 98/100\n",
            "6400/6400 [==============================] - 2s 326us/step - loss: 0.0949 - acc: 0.9937 - val_loss: 0.3742 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.96188\n",
            "Epoch 99/100\n",
            "6400/6400 [==============================] - 2s 304us/step - loss: 0.0961 - acc: 0.9930 - val_loss: 0.3846 - val_acc: 0.9569\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.96188\n",
            "Epoch 100/100\n",
            "6400/6400 [==============================] - 2s 321us/step - loss: 0.0962 - acc: 0.9933 - val_loss: 0.3742 - val_acc: 0.9569\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.96188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piGN3LFuBu1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_model.save_weights('full_model_pretrained_voices_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO52VtthCpTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "40e10482-6e6d-49ea-c927-004d29b32873"
      },
      "source": [
        "accuracy = pretrained_classifier_train.history['acc']\n",
        "val_accuracy = pretrained_classifier_train.history['val_acc']\n",
        "loss = pretrained_classifier_train.history['loss']\n",
        "val_loss = pretrained_classifier_train.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label = 'Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label = 'Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy using Pretrained Autoencoder Weights')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label = 'Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n",
        "plt.title('Training and Validation Loss using Pretrained Autoencoder Weights')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAAEICAYAAADMa/SXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEICAYAAAAUZ1CdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFAfo35rCt2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_eval = full_model.evaluate(X_test, y_test, verbose = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRimV9ZRC1D_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a0108667-0a37-4822-df49-be5fca2d96ec"
      },
      "source": [
        "print('Test loss : ', test_eval[0])\n",
        "print('Test accuracy : ', test_eval[1])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss :  0.3654981872854987\n",
            "Test accuracy :  0.959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoFbTLbmC3T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_classes = full_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tgV0AVCC6xM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_classes = np.argmax(np.round(predicted_classes), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Ng03I3C8ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_classes = lb.inverse_transform(predicted_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCU_bcBoDRdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['predicted_classes'] = predicted_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kds5r22aDT-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "768f8af4-a158-4a8d-c0c2-48a710d8eac3"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_labels</th>\n",
              "      <th>predicted_classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1624</td>\n",
              "      <td>1624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5163</td>\n",
              "      <td>5163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>201</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4160</td>\n",
              "      <td>4160</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  test_labels predicted_classes\n",
              "0         103               103\n",
              "1        1624              1624\n",
              "2        5163              5163\n",
              "3         201               201\n",
              "4        4160              4160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fleCnAUTDWEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f045efb1-74e3-4714-820f-9ad21db95258"
      },
      "source": [
        "test_df[test_df['test_labels'] != test_df['predicted_classes']]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_labels</th>\n",
              "      <th>predicted_classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7902</td>\n",
              "      <td>374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>8797</td>\n",
              "      <td>5703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>2182</td>\n",
              "      <td>4852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>446</td>\n",
              "      <td>4323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>89</td>\n",
              "      <td>4852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1903</th>\n",
              "      <td>2182</td>\n",
              "      <td>4852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>3112</td>\n",
              "      <td>6476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1924</th>\n",
              "      <td>446</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1928</th>\n",
              "      <td>4515</td>\n",
              "      <td>6818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1931</th>\n",
              "      <td>2182</td>\n",
              "      <td>4852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>85 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     test_labels predicted_classes\n",
              "6           7902               374\n",
              "51          8797              5703\n",
              "81          2182              4852\n",
              "83           446              4323\n",
              "86            89              4852\n",
              "...          ...               ...\n",
              "1903        2182              4852\n",
              "1912        3112              6476\n",
              "1924         446                61\n",
              "1928        4515              6818\n",
              "1931        2182              4852\n",
              "\n",
              "[85 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCL1TBluDbCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4b62bc3-0bef-413b-a1d2-06d4b0599d9e"
      },
      "source": [
        "1-round(len(test_df[test_df['test_labels'] != test_df['predicted_classes']])/len(test_df),3)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_VYc417DlIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}