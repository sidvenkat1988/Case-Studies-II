{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Voice_Model.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"L_zaZdkPAfBU","colab_type":"code","outputId":"963eb83e-d820-4384-9082-9c5e7d46981b","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd drive/My\\ Drive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SiXp-kbdAwDG","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mvj7_18gAxP3","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TwPsOcpByvp","colab_type":"code","outputId":"02e86502-52c1-4b13-c0a3-c43e4b0698d9","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd case\\ studies\\ 2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/case studies 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l2dvsQkVB6Yf","colab_type":"code","outputId":"965148b8-4592-46bb-945c-a1f43aa947a1","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["'1-Gathering Data.ipynb'\t       'Face Dataset'\n","'2-Gathering files information.ipynb'   Final_Data\n","'3-Data Pre-Processing.ipynb'\t        Final_Face_Dataset\n","'4-Gathering Raw Waveforms.ipynb'       mel_spectrograms\n","'5-Concatenating Raw Waveforms.ipynb'   Models\n","'Data Augmentation'\t\t        raw_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hoR7VCugB7yG","colab_type":"code","outputId":"71a79d29-e5ec-4bbd-b8a1-0040a326303c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd Models/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/case studies 2/Models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4WNXur2dB_6g","colab_type":"code","outputId":"467b7d81-e6ac-4c1e-96e2-6f8c4e0df07a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd Face\\ Models"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/case studies 2/Models/Face Models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NtK-YYuMCCZY","colab_type":"code","outputId":"42636e7a-883d-4b92-ca2e-3759889b2e87","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["face_test_data.npy   face_train_data.npy   Trial\n","face_test_label.npy  face_train_label.npy  Untitled\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vnd3xlJVCD6C","colab_type":"code","outputId":"0122598c-a96e-4d10-9c38-e3a638098035","colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import pandas as pd\n","import numpy as np\n","from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Flatten, BatchNormalization, Activation\n","from keras.models import Model\n","from keras import backend as K\n","from keras.utils.np_utils import to_categorical\n","\n","from keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import cv2\n","from sklearn.preprocessing import LabelEncoder"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"1MEFqj97Cifq","colab_type":"code","colab":{}},"source":["train_data = np.load('training_data.npy', allow_pickle=True)\n","train_labels = np.load('training_labels.npy', allow_pickle = True)\n","test_data = np.load('test_data.npy', allow_pickle = True)\n","test_labels = np.load('test_labels.npy', allow_pickle = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Utu5fZO0Clfj","colab_type":"code","outputId":"3a62c058-8237-4a7f-eeec-fcddcbcafca8","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["face_test_data.npy   face_train_data.npy   Trial\n","face_test_label.npy  face_train_label.npy  Untitled\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-x_ApY6-CpSZ","colab_type":"code","outputId":"652d2354-0c24-425d-8f42-10469fd3e12f","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd .."],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/case studies 2/Models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DkG41HgaCs2N","colab_type":"code","outputId":"6b7091e3-847f-47c9-d9a3-e52a9dacef32","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd Voice\\ Models"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/case studies 2/Models/Voice Models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-jpOsv9yCvjk","colab_type":"code","colab":{}},"source":["train_data = np.load('training_data.npy', allow_pickle=True)\n","train_labels = np.load('training_labels.npy', allow_pickle = True)\n","test_data = np.load('test_data.npy', allow_pickle = True)\n","test_labels = np.load('test_labels.npy', allow_pickle = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fomyfJpsCyDn","colab_type":"code","colab":{}},"source":["train_df = pd.DataFrame(columns = ['train_labels'])\n","train_df['train_labels'] = train_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GGR5knJ6C0PS","colab_type":"code","colab":{}},"source":["test_df = pd.DataFrame(columns = ['test_labels'])\n","test_df['test_labels'] = test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Mbx5zpvC2Eq","colab_type":"code","colab":{}},"source":["X = train_data/255.0\n","X_test = test_data/255.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Il8mwd44C34X","colab_type":"code","colab":{}},"source":["y = train_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1nt688bC5fI","colab_type":"code","colab":{}},"source":["y_test = test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BKzSEqY-C7g7","colab_type":"code","colab":{}},"source":["lb = LabelEncoder()\n","y = to_categorical(lb.fit_transform(y))\n","y_test = to_categorical(lb.fit_transform(y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R5VuijvyC9Ou","colab_type":"code","colab":{}},"source":["X_train = X[:24000]\n","y_train = y[:24000]\n","X_val = X[24000:]\n","y_val = y[24000:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvuQuWRzC_Dg","colab_type":"code","outputId":"72d84acf-78c5-45f5-c617-44dfc6b8204a","colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["input_img = Input(shape = (64, 64, 3))\n","x = Conv2D(32, (3,3), activation = 'relu', padding = 'same')(input_img)\n","x = BatchNormalization()(x)\n","x = Conv2D(32, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Conv2D(64, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(64, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Conv2D(256, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(256, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Conv2D(512, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(512, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","encoded = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Conv2D(512, (3,3), activation = 'relu', padding = 'same')(encoded)\n","x = BatchNormalization()(x)\n","x = Conv2D(512, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = UpSampling2D((2,2))(x)\n","\n","x = Conv2D(256, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(256, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = UpSampling2D((2,2))(x)\n","\n","x = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = UpSampling2D((2,2))(x)\n","\n","x = Conv2D(64, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(64, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = UpSampling2D((2,2))(x)\n","\n","x = Conv2D(32, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(32, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = UpSampling2D((2,2))(x)\n","\n","decoded = Conv2D(3, (3,3), activation = 'softmax', padding = 'same')(x)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8XHjmGIqDAkp","colab_type":"code","outputId":"d1301a70-13a0-4788-be3c-633155eddc18","colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["autoencoder = Model(input_img, decoded)\n","autoencoder.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dClVb3PUDCwJ","colab_type":"code","outputId":"05a4caaa-46d2-4d2c-a605-7d7bd253c75b","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["autoencoder.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 64, 64, 3)         0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 64, 64, 32)        128       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 64, 64, 32)        9248      \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 64, 64, 32)        128       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 4, 4, 512)         2048      \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 4, 4, 256)         1179904   \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 4, 4, 256)         590080    \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 8, 8, 128)         295040    \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv2d_16 (Conv2D)           (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","up_sampling2d_3 (UpSampling2 (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 16, 16, 64)        73792     \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv2d_18 (Conv2D)           (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","up_sampling2d_4 (UpSampling2 (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 32, 32, 32)        18464     \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 32, 32, 32)        128       \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 32, 32, 32)        9248      \n","_________________________________________________________________\n","batch_normalization_20 (Batc (None, 32, 32, 32)        128       \n","_________________________________________________________________\n","up_sampling2d_5 (UpSampling2 (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","conv2d_21 (Conv2D)           (None, 64, 64, 3)         867       \n","=================================================================\n","Total params: 11,799,619\n","Trainable params: 11,791,683\n","Non-trainable params: 7,936\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-wR5vgFhDE_t","colab_type":"code","colab":{}},"source":["filepath = 'voice_autoencoder.h5'\n","checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JKB-ZrhcDHy3","colab_type":"code","outputId":"5ca4d8b1-b94f-4266-e55b-a03edc47d08b","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["autoencoder_train = autoencoder.fit(X_train, X_train, epochs = 100, batch_size = 256, verbose = 1, callbacks = callbacks_list, validation_data = [X_val, X_val])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 24000 samples, validate on 8000 samples\n","Epoch 1/100\n","24000/24000 [==============================] - 48s 2ms/step - loss: 1.0551 - acc: 0.6694 - val_loss: 1.0461 - val_acc: 0.7347\n","\n","Epoch 00001: val_acc improved from -inf to 0.73467, saving model to voice_autoencoder.h5\n","Epoch 2/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0302 - acc: 0.8010 - val_loss: 1.0432 - val_acc: 0.7168\n","\n","Epoch 00002: val_acc did not improve from 0.73467\n","Epoch 3/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0255 - acc: 0.8374 - val_loss: 1.0327 - val_acc: 0.8197\n","\n","Epoch 00003: val_acc improved from 0.73467 to 0.81967, saving model to voice_autoencoder.h5\n","Epoch 4/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0232 - acc: 0.8550 - val_loss: 1.0297 - val_acc: 0.8501\n","\n","Epoch 00004: val_acc improved from 0.81967 to 0.85014, saving model to voice_autoencoder.h5\n","Epoch 5/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0217 - acc: 0.8657 - val_loss: 1.0272 - val_acc: 0.8634\n","\n","Epoch 00005: val_acc improved from 0.85014 to 0.86336, saving model to voice_autoencoder.h5\n","Epoch 6/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0208 - acc: 0.8722 - val_loss: 1.0260 - val_acc: 0.8719\n","\n","Epoch 00006: val_acc improved from 0.86336 to 0.87187, saving model to voice_autoencoder.h5\n","Epoch 7/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0202 - acc: 0.8764 - val_loss: 1.0262 - val_acc: 0.8781\n","\n","Epoch 00007: val_acc improved from 0.87187 to 0.87807, saving model to voice_autoencoder.h5\n","Epoch 8/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0200 - acc: 0.8783 - val_loss: 1.0423 - val_acc: 0.8497\n","\n","Epoch 00008: val_acc did not improve from 0.87807\n","Epoch 9/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0196 - acc: 0.8800 - val_loss: 1.0316 - val_acc: 0.8619\n","\n","Epoch 00009: val_acc did not improve from 0.87807\n","Epoch 10/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0192 - acc: 0.8836 - val_loss: 1.0263 - val_acc: 0.8806\n","\n","Epoch 00010: val_acc improved from 0.87807 to 0.88061, saving model to voice_autoencoder.h5\n","Epoch 11/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0183 - acc: 0.8896 - val_loss: 1.0238 - val_acc: 0.8871\n","\n","Epoch 00011: val_acc improved from 0.88061 to 0.88710, saving model to voice_autoencoder.h5\n","Epoch 12/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0180 - acc: 0.8920 - val_loss: 1.0235 - val_acc: 0.8914\n","\n","Epoch 00012: val_acc improved from 0.88710 to 0.89144, saving model to voice_autoencoder.h5\n","Epoch 13/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0175 - acc: 0.8955 - val_loss: 1.0231 - val_acc: 0.8945\n","\n","Epoch 00013: val_acc improved from 0.89144 to 0.89453, saving model to voice_autoencoder.h5\n","Epoch 14/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0171 - acc: 0.8979 - val_loss: 1.0230 - val_acc: 0.8946\n","\n","Epoch 00014: val_acc improved from 0.89453 to 0.89464, saving model to voice_autoencoder.h5\n","Epoch 15/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0169 - acc: 0.8991 - val_loss: 1.0223 - val_acc: 0.8984\n","\n","Epoch 00015: val_acc improved from 0.89464 to 0.89838, saving model to voice_autoencoder.h5\n","Epoch 16/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0167 - acc: 0.9008 - val_loss: 1.0223 - val_acc: 0.8981\n","\n","Epoch 00016: val_acc did not improve from 0.89838\n","Epoch 17/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0165 - acc: 0.9017 - val_loss: 1.0223 - val_acc: 0.9016\n","\n","Epoch 00017: val_acc improved from 0.89838 to 0.90156, saving model to voice_autoencoder.h5\n","Epoch 18/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0163 - acc: 0.9030 - val_loss: 1.0229 - val_acc: 0.8953\n","\n","Epoch 00018: val_acc did not improve from 0.90156\n","Epoch 19/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0162 - acc: 0.9039 - val_loss: 1.0229 - val_acc: 0.8972\n","\n","Epoch 00019: val_acc did not improve from 0.90156\n","Epoch 20/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0171 - acc: 0.8977 - val_loss: 5.3073 - val_acc: 0.5077\n","\n","Epoch 00020: val_acc did not improve from 0.90156\n","Epoch 21/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0170 - acc: 0.8989 - val_loss: 1.0315 - val_acc: 0.8698\n","\n","Epoch 00021: val_acc did not improve from 0.90156\n","Epoch 22/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0162 - acc: 0.9035 - val_loss: 1.0244 - val_acc: 0.8931\n","\n","Epoch 00022: val_acc did not improve from 0.90156\n","Epoch 23/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0160 - acc: 0.9051 - val_loss: 1.0221 - val_acc: 0.8976\n","\n","Epoch 00023: val_acc did not improve from 0.90156\n","Epoch 24/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0157 - acc: 0.9064 - val_loss: 1.0217 - val_acc: 0.9016\n","\n","Epoch 00024: val_acc improved from 0.90156 to 0.90159, saving model to voice_autoencoder.h5\n","Epoch 25/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0156 - acc: 0.9069 - val_loss: 1.0215 - val_acc: 0.9054\n","\n","Epoch 00025: val_acc improved from 0.90159 to 0.90536, saving model to voice_autoencoder.h5\n","Epoch 26/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0154 - acc: 0.9085 - val_loss: 1.0214 - val_acc: 0.9020\n","\n","Epoch 00026: val_acc did not improve from 0.90536\n","Epoch 27/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0152 - acc: 0.9095 - val_loss: 1.0209 - val_acc: 0.9065\n","\n","Epoch 00027: val_acc improved from 0.90536 to 0.90648, saving model to voice_autoencoder.h5\n","Epoch 28/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0152 - acc: 0.9089 - val_loss: 1.0207 - val_acc: 0.9076\n","\n","Epoch 00028: val_acc improved from 0.90648 to 0.90758, saving model to voice_autoencoder.h5\n","Epoch 29/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0151 - acc: 0.9100 - val_loss: 1.0204 - val_acc: 0.9088\n","\n","Epoch 00029: val_acc improved from 0.90758 to 0.90882, saving model to voice_autoencoder.h5\n","Epoch 30/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0149 - acc: 0.9105 - val_loss: 1.0205 - val_acc: 0.9104\n","\n","Epoch 00030: val_acc improved from 0.90882 to 0.91036, saving model to voice_autoencoder.h5\n","Epoch 31/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0148 - acc: 0.9109 - val_loss: 1.0206 - val_acc: 0.9076\n","\n","Epoch 00031: val_acc did not improve from 0.91036\n","Epoch 32/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0148 - acc: 0.9111 - val_loss: 1.0207 - val_acc: 0.9064\n","\n","Epoch 00032: val_acc did not improve from 0.91036\n","Epoch 33/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0147 - acc: 0.9114 - val_loss: 1.0210 - val_acc: 0.9038\n","\n","Epoch 00033: val_acc did not improve from 0.91036\n","Epoch 34/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0146 - acc: 0.9121 - val_loss: 1.0204 - val_acc: 0.9096\n","\n","Epoch 00034: val_acc did not improve from 0.91036\n","Epoch 35/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0146 - acc: 0.9118 - val_loss: 1.0200 - val_acc: 0.9131\n","\n","Epoch 00035: val_acc improved from 0.91036 to 0.91306, saving model to voice_autoencoder.h5\n","Epoch 36/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0144 - acc: 0.9132 - val_loss: 1.0199 - val_acc: 0.9120\n","\n","Epoch 00036: val_acc did not improve from 0.91306\n","Epoch 37/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0143 - acc: 0.9142 - val_loss: 1.0205 - val_acc: 0.9044\n","\n","Epoch 00037: val_acc did not improve from 0.91306\n","Epoch 38/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0143 - acc: 0.9137 - val_loss: 1.0206 - val_acc: 0.9063\n","\n","Epoch 00038: val_acc did not improve from 0.91306\n","Epoch 39/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0142 - acc: 0.9148 - val_loss: 1.0207 - val_acc: 0.9061\n","\n","Epoch 00039: val_acc did not improve from 0.91306\n","Epoch 40/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0141 - acc: 0.9150 - val_loss: 1.0200 - val_acc: 0.9137\n","\n","Epoch 00040: val_acc improved from 0.91306 to 0.91367, saving model to voice_autoencoder.h5\n","Epoch 41/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0140 - acc: 0.9152 - val_loss: 1.0197 - val_acc: 0.9117\n","\n","Epoch 00041: val_acc did not improve from 0.91367\n","Epoch 42/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0140 - acc: 0.9153 - val_loss: 1.0207 - val_acc: 0.9058\n","\n","Epoch 00042: val_acc did not improve from 0.91367\n","Epoch 43/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0147 - acc: 0.9102 - val_loss: 1.0213 - val_acc: 0.9038\n","\n","Epoch 00043: val_acc did not improve from 0.91367\n","Epoch 44/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0140 - acc: 0.9149 - val_loss: 1.0216 - val_acc: 0.9125\n","\n","Epoch 00044: val_acc did not improve from 0.91367\n","Epoch 45/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0139 - acc: 0.9157 - val_loss: 1.0203 - val_acc: 0.9062\n","\n","Epoch 00045: val_acc did not improve from 0.91367\n","Epoch 46/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0138 - acc: 0.9163 - val_loss: 1.0200 - val_acc: 0.9129\n","\n","Epoch 00046: val_acc did not improve from 0.91367\n","Epoch 47/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0137 - acc: 0.9165 - val_loss: 1.0202 - val_acc: 0.9146\n","\n","Epoch 00047: val_acc improved from 0.91367 to 0.91463, saving model to voice_autoencoder.h5\n","Epoch 48/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0136 - acc: 0.9170 - val_loss: 1.0198 - val_acc: 0.9122\n","\n","Epoch 00048: val_acc did not improve from 0.91463\n","Epoch 49/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0135 - acc: 0.9184 - val_loss: 1.0193 - val_acc: 0.9141\n","\n","Epoch 00049: val_acc did not improve from 0.91463\n","Epoch 50/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0135 - acc: 0.9182 - val_loss: 1.0206 - val_acc: 0.9147\n","\n","Epoch 00050: val_acc improved from 0.91463 to 0.91470, saving model to voice_autoencoder.h5\n","Epoch 51/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0134 - acc: 0.9182 - val_loss: 1.0193 - val_acc: 0.9123\n","\n","Epoch 00051: val_acc did not improve from 0.91470\n","Epoch 52/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0135 - acc: 0.9181 - val_loss: 1.0198 - val_acc: 0.9136\n","\n","Epoch 00052: val_acc did not improve from 0.91470\n","Epoch 53/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0133 - acc: 0.9190 - val_loss: 1.0196 - val_acc: 0.9130\n","\n","Epoch 00053: val_acc did not improve from 0.91470\n","Epoch 54/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0133 - acc: 0.9192 - val_loss: 1.0194 - val_acc: 0.9116\n","\n","Epoch 00054: val_acc did not improve from 0.91470\n","Epoch 55/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0134 - acc: 0.9188 - val_loss: 1.0204 - val_acc: 0.9061\n","\n","Epoch 00055: val_acc did not improve from 0.91470\n","Epoch 56/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0133 - acc: 0.9194 - val_loss: 1.0198 - val_acc: 0.9156\n","\n","Epoch 00056: val_acc improved from 0.91470 to 0.91555, saving model to voice_autoencoder.h5\n","Epoch 57/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0132 - acc: 0.9198 - val_loss: 1.0203 - val_acc: 0.9046\n","\n","Epoch 00057: val_acc did not improve from 0.91555\n","Epoch 58/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0130 - acc: 0.9207 - val_loss: 1.0193 - val_acc: 0.9155\n","\n","Epoch 00058: val_acc did not improve from 0.91555\n","Epoch 59/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0131 - acc: 0.9203 - val_loss: 1.0193 - val_acc: 0.9099\n","\n","Epoch 00059: val_acc did not improve from 0.91555\n","Epoch 60/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0136 - acc: 0.9169 - val_loss: 1.0270 - val_acc: 0.8882\n","\n","Epoch 00060: val_acc did not improve from 0.91555\n","Epoch 61/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0132 - acc: 0.9191 - val_loss: 1.0227 - val_acc: 0.9022\n","\n","Epoch 00061: val_acc did not improve from 0.91555\n","Epoch 62/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0131 - acc: 0.9201 - val_loss: 1.0212 - val_acc: 0.9161\n","\n","Epoch 00062: val_acc improved from 0.91555 to 0.91612, saving model to voice_autoencoder.h5\n","Epoch 63/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0130 - acc: 0.9210 - val_loss: 1.0190 - val_acc: 0.9155\n","\n","Epoch 00063: val_acc did not improve from 0.91612\n","Epoch 64/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0129 - acc: 0.9213 - val_loss: 1.0196 - val_acc: 0.9141\n","\n","Epoch 00064: val_acc did not improve from 0.91612\n","Epoch 65/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0128 - acc: 0.9218 - val_loss: 1.0198 - val_acc: 0.9167\n","\n","Epoch 00065: val_acc improved from 0.91612 to 0.91673, saving model to voice_autoencoder.h5\n","Epoch 66/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0127 - acc: 0.9229 - val_loss: 1.0194 - val_acc: 0.9154\n","\n","Epoch 00066: val_acc did not improve from 0.91673\n","Epoch 67/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0128 - acc: 0.9220 - val_loss: 1.0207 - val_acc: 0.9094\n","\n","Epoch 00067: val_acc did not improve from 0.91673\n","Epoch 68/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0127 - acc: 0.9225 - val_loss: 1.0187 - val_acc: 0.9168\n","\n","Epoch 00068: val_acc improved from 0.91673 to 0.91679, saving model to voice_autoencoder.h5\n","Epoch 69/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0127 - acc: 0.9225 - val_loss: 1.0194 - val_acc: 0.9184\n","\n","Epoch 00069: val_acc improved from 0.91679 to 0.91843, saving model to voice_autoencoder.h5\n","Epoch 70/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0126 - acc: 0.9232 - val_loss: 1.0200 - val_acc: 0.9184\n","\n","Epoch 00070: val_acc did not improve from 0.91843\n","Epoch 71/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0126 - acc: 0.9230 - val_loss: 1.0198 - val_acc: 0.9060\n","\n","Epoch 00071: val_acc did not improve from 0.91843\n","Epoch 72/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0126 - acc: 0.9234 - val_loss: 1.0192 - val_acc: 0.9178\n","\n","Epoch 00072: val_acc did not improve from 0.91843\n","Epoch 73/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0125 - acc: 0.9240 - val_loss: 1.0195 - val_acc: 0.9184\n","\n","Epoch 00073: val_acc did not improve from 0.91843\n","Epoch 74/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0125 - acc: 0.9241 - val_loss: 1.0190 - val_acc: 0.9184\n","\n","Epoch 00074: val_acc did not improve from 0.91843\n","Epoch 75/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0124 - acc: 0.9242 - val_loss: 1.0198 - val_acc: 0.9205\n","\n","Epoch 00075: val_acc improved from 0.91843 to 0.92054, saving model to voice_autoencoder.h5\n","Epoch 76/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0123 - acc: 0.9247 - val_loss: 1.0192 - val_acc: 0.9210\n","\n","Epoch 00076: val_acc improved from 0.92054 to 0.92097, saving model to voice_autoencoder.h5\n","Epoch 77/100\n","23808/24000 [============================>.] - ETA: 0s - loss: 1.0124 - acc: 0.9254\n","Epoch 00077: val_acc improved from 0.92097 to 0.92154, saving model to voice_autoencoder.h5\n","Epoch 78/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0122 - acc: 0.9258 - val_loss: 1.0179 - val_acc: 0.9218\n","\n","Epoch 00078: val_acc improved from 0.92154 to 0.92181, saving model to voice_autoencoder.h5\n","Epoch 79/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0122 - acc: 0.9255 - val_loss: 1.0186 - val_acc: 0.9191\n","\n","Epoch 00079: val_acc did not improve from 0.92181\n","Epoch 80/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0121 - acc: 0.9262 - val_loss: 1.0185 - val_acc: 0.9214\n","\n","Epoch 00080: val_acc did not improve from 0.92181\n","Epoch 81/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0121 - acc: 0.9264 - val_loss: 1.0183 - val_acc: 0.9219\n","\n","Epoch 00081: val_acc improved from 0.92181 to 0.92189, saving model to voice_autoencoder.h5\n","Epoch 82/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0121 - acc: 0.9268 - val_loss: 1.0188 - val_acc: 0.9123\n","\n","Epoch 00082: val_acc did not improve from 0.92189\n","Epoch 83/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0121 - acc: 0.9262 - val_loss: 1.0194 - val_acc: 0.9173\n","\n","Epoch 00083: val_acc did not improve from 0.92189\n","Epoch 84/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0120 - acc: 0.9270 - val_loss: 1.0184 - val_acc: 0.9234\n","\n","Epoch 00084: val_acc improved from 0.92189 to 0.92340, saving model to voice_autoencoder.h5\n","Epoch 85/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0120 - acc: 0.9275 - val_loss: 1.0184 - val_acc: 0.9208\n","\n","Epoch 00085: val_acc did not improve from 0.92340\n","Epoch 86/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0119 - acc: 0.9275 - val_loss: 1.0188 - val_acc: 0.9187\n","\n","Epoch 00086: val_acc did not improve from 0.92340\n","Epoch 87/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0119 - acc: 0.9279 - val_loss: 1.0191 - val_acc: 0.9191\n","\n","Epoch 00087: val_acc did not improve from 0.92340\n","Epoch 88/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0119 - acc: 0.9275 - val_loss: 1.0182 - val_acc: 0.9191\n","\n","Epoch 00088: val_acc did not improve from 0.92340\n","Epoch 89/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0119 - acc: 0.9279 - val_loss: 1.0182 - val_acc: 0.9218\n","\n","Epoch 00089: val_acc did not improve from 0.92340\n","Epoch 90/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0117 - acc: 0.9290 - val_loss: 1.0174 - val_acc: 0.9268\n","\n","Epoch 00090: val_acc improved from 0.92340 to 0.92680, saving model to voice_autoencoder.h5\n","Epoch 91/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0118 - acc: 0.9283 - val_loss: 1.0177 - val_acc: 0.9255\n","\n","Epoch 00091: val_acc did not improve from 0.92680\n","Epoch 92/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0118 - acc: 0.9285 - val_loss: 1.0175 - val_acc: 0.9238\n","\n","Epoch 00092: val_acc did not improve from 0.92680\n","Epoch 93/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0117 - acc: 0.9287 - val_loss: 1.0177 - val_acc: 0.9253\n","\n","Epoch 00093: val_acc did not improve from 0.92680\n","Epoch 94/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0116 - acc: 0.9295 - val_loss: 1.0180 - val_acc: 0.9251\n","\n","Epoch 00094: val_acc did not improve from 0.92680\n","Epoch 95/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0117 - acc: 0.9288 - val_loss: 1.0176 - val_acc: 0.9214\n","\n","Epoch 00095: val_acc did not improve from 0.92680\n","Epoch 96/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0116 - acc: 0.9293 - val_loss: 1.0174 - val_acc: 0.9253\n","\n","Epoch 00096: val_acc did not improve from 0.92680\n","Epoch 97/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0116 - acc: 0.9293 - val_loss: 1.0176 - val_acc: 0.9253\n","\n","Epoch 00097: val_acc did not improve from 0.92680\n","Epoch 98/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0117 - acc: 0.9287 - val_loss: 1.0177 - val_acc: 0.9261\n","\n","Epoch 00098: val_acc did not improve from 0.92680\n","Epoch 99/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0116 - acc: 0.9299 - val_loss: 1.0174 - val_acc: 0.9236\n","\n","Epoch 00099: val_acc did not improve from 0.92680\n","Epoch 100/100\n","24000/24000 [==============================] - 28s 1ms/step - loss: 1.0116 - acc: 0.9295 - val_loss: 1.0176 - val_acc: 0.9252\n","\n","Epoch 00100: val_acc did not improve from 0.92680\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gLAf4MwKDJyX","colab_type":"code","outputId":"bc32c947-7aa2-4435-dee9-425db0a316f3","colab":{"base_uri":"https://localhost:8080/","height":281}},"source":["loss = autoencoder_train.history['loss']\n","val_loss = autoencoder_train.history['val_loss']\n","epochs = range(100)\n","plt.figure()\n","plt.plot(epochs, loss, 'bo', label = 'Training Loss')\n","plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n","plt.title('Training and Validation Loss for Autoencoder Voices Model')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZUKBLiJSJv4/2giCYeW4pUwAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"jVc65BlOGL-S","colab_type":"code","colab":{}},"source":["autoencoder.save_weights('Autoencoder_Voices_Weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TrMiV9KGW94","colab_type":"code","colab":{}},"source":["input_img = Input(shape = (64, 64, 3))\n","x = Conv2D(32, (3,3), activation = 'relu', padding = 'same')(input_img)\n","x = BatchNormalization()(x)\n","x = Conv2D(32, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Conv2D(64, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(64, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Conv2D(256, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(256, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Conv2D(512, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(512, (3,3), activation = 'relu', padding = 'same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2,2), padding = 'same')(x)\n","\n","x = Flatten()(x)\n","x = Dense(128, activation = 'relu')(x)\n","output = Dense(160, activation = 'softmax')(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Dskwmn4GiYz","colab_type":"code","colab":{}},"source":["full_model = Model(input_img, output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SiprmyyzGs_f","colab_type":"code","outputId":"2b525cb8-cdf5-4981-ff51-7e9218182bbc","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(full_model.layers)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["29"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"trYpqnE_OXV5","colab_type":"code","colab":{}},"source":["for l1, l2 in zip(full_model.layers[:26], autoencoder.layers[0:26]):\n","  l1.set_weights(l2.get_weights())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6BqNRuWOjfX","colab_type":"code","outputId":"6e14f0f5-3c66-4686-d55b-1f255e1555c1","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["autoencoder.get_weights()[0][1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[-1.37625905e-02, -1.29738748e-01,  7.77044967e-02,\n","         -6.62038326e-02, -5.62239945e-01, -2.45890003e-02,\n","          6.00689985e-02,  1.00667417e-01,  1.88464429e-02,\n","         -7.88812805e-03, -6.61211684e-02,  4.40740027e-02,\n","          1.13965467e-01,  1.01051904e-01,  8.39714557e-02,\n","         -7.28666484e-02, -8.41181353e-02, -2.63784137e-02,\n","         -1.15087749e-02, -5.76011650e-02, -9.83508304e-02,\n","         -1.10937975e-01, -1.26110181e-01, -5.52679263e-02,\n","          1.92155555e-01, -7.96650574e-02,  1.14065461e-01,\n","          1.06533334e-01,  7.49313161e-02,  4.25698468e-03,\n","          9.68482718e-02, -6.90288022e-02],\n","        [ 1.33893698e-01, -7.12839812e-02, -6.73973411e-02,\n","          1.82284102e-01, -2.89483786e-01, -1.28497571e-01,\n","          8.62966552e-02,  1.58490032e-01, -9.95955020e-02,\n","         -3.84759940e-02, -7.78776333e-02,  6.10330664e-02,\n","          1.26747698e-01, -2.52002999e-02, -7.39362016e-02,\n","         -1.43045885e-02,  1.27240404e-01,  1.32562712e-01,\n","         -3.48351151e-02,  1.23757385e-01, -2.94225086e-02,\n","          5.46097830e-02,  3.83660942e-02,  1.35447279e-01,\n","          7.21221194e-02,  1.37595996e-01,  4.20486816e-04,\n","          5.54103069e-02,  7.70323025e-03, -3.29412483e-02,\n","         -1.01530544e-01,  7.86910355e-02],\n","        [ 2.75259167e-02,  5.63245825e-02,  6.34467006e-02,\n","         -3.08546256e-02, -1.53173357e-01,  1.19165584e-01,\n","         -4.84420955e-02, -5.67303933e-02, -5.62238432e-02,\n","         -2.11665574e-02, -1.62118822e-02, -8.14610999e-03,\n","         -9.23379138e-02, -2.50420719e-02,  9.09973085e-02,\n","          1.74020627e-03,  9.77559984e-02, -1.12611875e-01,\n","          1.84176099e-02,  1.25772189e-02,  5.58687150e-02,\n","         -1.99885536e-02, -1.86946303e-01, -3.26275229e-02,\n","          1.41875863e-01,  2.80951560e-02, -2.05053035e-02,\n","         -2.44002286e-02,  1.03296936e-02,  8.76112431e-02,\n","          1.12603232e-01, -1.93779543e-02]],\n","\n","       [[ 9.51828584e-02, -1.03434190e-01,  3.24005149e-02,\n","          3.47566642e-02, -4.85349566e-01, -4.46949974e-02,\n","         -7.17551559e-02,  1.04109533e-01,  5.86794838e-02,\n","          2.12139878e-02,  1.42790437e-01, -1.06619271e-02,\n","         -8.32706690e-02, -1.40088171e-01, -5.94400056e-02,\n","         -4.64501195e-02,  6.67858571e-02,  1.13152400e-01,\n","         -3.93232778e-02,  1.14807367e-01, -2.30381619e-02,\n","         -9.34489891e-02,  1.48913115e-02,  7.72087127e-02,\n","          1.95625089e-02, -3.34734730e-02, -6.23114891e-02,\n","         -6.88593760e-02,  1.12266324e-01,  1.38822272e-01,\n","          2.62589231e-02, -2.32889354e-02],\n","        [ 7.27371797e-02,  4.49868180e-02,  5.89837469e-02,\n","          1.24116570e-01, -2.27406412e-01, -1.25145484e-02,\n","         -1.02914274e-01,  1.82200700e-01, -3.08356732e-02,\n","          2.76354980e-02,  2.26802573e-01, -4.97840270e-02,\n","         -1.20525301e-01,  3.26145515e-02,  1.43559158e-01,\n","          3.55193880e-03,  1.05330035e-01, -2.17014123e-02,\n","          1.47063345e-01,  1.46764874e-01,  8.68142396e-02,\n","          1.04923233e-01,  1.32866547e-01, -9.18605644e-03,\n","         -1.25339299e-01, -1.06080048e-01,  2.31355075e-02,\n","         -4.60070670e-02,  1.70758620e-01,  2.43019518e-02,\n","         -1.27761573e-01,  8.98198262e-02],\n","        [ 9.95870903e-02,  9.66718197e-02, -7.24573582e-02,\n","          8.45807046e-02,  1.54063717e-01,  1.12338550e-01,\n","         -7.65244141e-02,  4.91280518e-02,  3.96742821e-02,\n","         -1.45121515e-01,  1.19953588e-01,  7.42163360e-02,\n","         -1.13956496e-01,  6.63054883e-02, -7.84708858e-02,\n","          1.22312881e-01,  1.06882431e-01,  2.75885593e-02,\n","         -5.45151345e-03, -9.03756917e-02,  1.22724168e-01,\n","          1.31920561e-01,  5.74101247e-02,  6.31859824e-02,\n","         -1.44468099e-01,  3.12954597e-02, -5.79852797e-02,\n","          9.76539925e-02, -9.90582258e-02,  5.48684932e-02,\n","          1.18582137e-01,  1.67561211e-02]],\n","\n","       [[ 6.96523711e-02,  9.51133072e-02,  3.83260548e-02,\n","         -5.53961545e-02, -3.67039323e-01, -3.79873882e-03,\n","         -3.77463698e-02, -9.33265090e-02,  1.11335084e-01,\n","          8.50162283e-02,  5.87407723e-02,  5.30881658e-02,\n","          7.25775864e-03,  1.02062315e-01,  1.43433124e-01,\n","         -5.78006804e-02, -1.19045444e-01, -6.00903966e-02,\n","          3.32476720e-02,  7.53503432e-03,  7.25210458e-02,\n","          8.00978243e-02,  1.55207552e-02, -4.05040830e-01,\n","          4.93789762e-02,  1.65580940e-02, -6.52524158e-02,\n","          3.23175006e-02, -4.22170609e-02,  7.45071156e-04,\n","          8.01340118e-02, -7.53863603e-02],\n","        [ 2.02840697e-02,  4.71455641e-02, -1.41292915e-01,\n","          1.82563402e-02, -3.87157440e-01,  1.26854047e-01,\n","          9.47140306e-02, -9.23017785e-03,  7.46181980e-02,\n","          1.12658747e-01,  9.80188772e-02,  3.21617983e-02,\n","         -9.01404843e-02,  7.28641152e-02,  1.64422423e-01,\n","          1.97462253e-02,  9.43850651e-02, -1.58866383e-02,\n","          9.64827016e-02, -2.40852106e-02, -5.61850928e-02,\n","          1.27013549e-01, -6.57607522e-03, -2.07259730e-01,\n","         -1.50331721e-01, -1.27493753e-03, -4.38441522e-03,\n","         -2.12110505e-02,  5.44657074e-02,  1.44705877e-01,\n","          1.71855316e-02, -5.53093432e-03],\n","        [-6.07071817e-02,  1.60668604e-02,  3.54671068e-02,\n","          5.38311750e-02, -1.24855854e-01, -7.43781449e-03,\n","         -8.82941037e-02,  3.41388993e-02, -8.64619464e-02,\n","         -4.48276363e-02,  9.23824310e-02,  2.69729225e-03,\n","         -1.37553453e-01, -1.03436284e-01, -5.36071211e-02,\n","         -4.97642271e-02,  1.19962431e-01, -1.03399716e-01,\n","         -1.26018226e-01, -6.87719975e-03,  6.22466095e-02,\n","         -6.42414344e-03,  1.09452598e-01, -2.88673013e-01,\n","         -8.79256576e-02,  3.01115997e-02, -1.15632243e-01,\n","         -1.09858334e-01,  8.04788321e-02,  3.90831679e-02,\n","          1.04585968e-01,  3.70089523e-02]]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"jaKQY2ciOvNM","colab_type":"code","outputId":"30056172-e6f5-4c4e-ceff-9218fb445f87","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["full_model.get_weights()[0][1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[-1.37625905e-02, -1.29738748e-01,  7.77044967e-02,\n","         -6.62038326e-02, -5.62239945e-01, -2.45890003e-02,\n","          6.00689985e-02,  1.00667417e-01,  1.88464429e-02,\n","         -7.88812805e-03, -6.61211684e-02,  4.40740027e-02,\n","          1.13965467e-01,  1.01051904e-01,  8.39714557e-02,\n","         -7.28666484e-02, -8.41181353e-02, -2.63784137e-02,\n","         -1.15087749e-02, -5.76011650e-02, -9.83508304e-02,\n","         -1.10937975e-01, -1.26110181e-01, -5.52679263e-02,\n","          1.92155555e-01, -7.96650574e-02,  1.14065461e-01,\n","          1.06533334e-01,  7.49313161e-02,  4.25698468e-03,\n","          9.68482718e-02, -6.90288022e-02],\n","        [ 1.33893698e-01, -7.12839812e-02, -6.73973411e-02,\n","          1.82284102e-01, -2.89483786e-01, -1.28497571e-01,\n","          8.62966552e-02,  1.58490032e-01, -9.95955020e-02,\n","         -3.84759940e-02, -7.78776333e-02,  6.10330664e-02,\n","          1.26747698e-01, -2.52002999e-02, -7.39362016e-02,\n","         -1.43045885e-02,  1.27240404e-01,  1.32562712e-01,\n","         -3.48351151e-02,  1.23757385e-01, -2.94225086e-02,\n","          5.46097830e-02,  3.83660942e-02,  1.35447279e-01,\n","          7.21221194e-02,  1.37595996e-01,  4.20486816e-04,\n","          5.54103069e-02,  7.70323025e-03, -3.29412483e-02,\n","         -1.01530544e-01,  7.86910355e-02],\n","        [ 2.75259167e-02,  5.63245825e-02,  6.34467006e-02,\n","         -3.08546256e-02, -1.53173357e-01,  1.19165584e-01,\n","         -4.84420955e-02, -5.67303933e-02, -5.62238432e-02,\n","         -2.11665574e-02, -1.62118822e-02, -8.14610999e-03,\n","         -9.23379138e-02, -2.50420719e-02,  9.09973085e-02,\n","          1.74020627e-03,  9.77559984e-02, -1.12611875e-01,\n","          1.84176099e-02,  1.25772189e-02,  5.58687150e-02,\n","         -1.99885536e-02, -1.86946303e-01, -3.26275229e-02,\n","          1.41875863e-01,  2.80951560e-02, -2.05053035e-02,\n","         -2.44002286e-02,  1.03296936e-02,  8.76112431e-02,\n","          1.12603232e-01, -1.93779543e-02]],\n","\n","       [[ 9.51828584e-02, -1.03434190e-01,  3.24005149e-02,\n","          3.47566642e-02, -4.85349566e-01, -4.46949974e-02,\n","         -7.17551559e-02,  1.04109533e-01,  5.86794838e-02,\n","          2.12139878e-02,  1.42790437e-01, -1.06619271e-02,\n","         -8.32706690e-02, -1.40088171e-01, -5.94400056e-02,\n","         -4.64501195e-02,  6.67858571e-02,  1.13152400e-01,\n","         -3.93232778e-02,  1.14807367e-01, -2.30381619e-02,\n","         -9.34489891e-02,  1.48913115e-02,  7.72087127e-02,\n","          1.95625089e-02, -3.34734730e-02, -6.23114891e-02,\n","         -6.88593760e-02,  1.12266324e-01,  1.38822272e-01,\n","          2.62589231e-02, -2.32889354e-02],\n","        [ 7.27371797e-02,  4.49868180e-02,  5.89837469e-02,\n","          1.24116570e-01, -2.27406412e-01, -1.25145484e-02,\n","         -1.02914274e-01,  1.82200700e-01, -3.08356732e-02,\n","          2.76354980e-02,  2.26802573e-01, -4.97840270e-02,\n","         -1.20525301e-01,  3.26145515e-02,  1.43559158e-01,\n","          3.55193880e-03,  1.05330035e-01, -2.17014123e-02,\n","          1.47063345e-01,  1.46764874e-01,  8.68142396e-02,\n","          1.04923233e-01,  1.32866547e-01, -9.18605644e-03,\n","         -1.25339299e-01, -1.06080048e-01,  2.31355075e-02,\n","         -4.60070670e-02,  1.70758620e-01,  2.43019518e-02,\n","         -1.27761573e-01,  8.98198262e-02],\n","        [ 9.95870903e-02,  9.66718197e-02, -7.24573582e-02,\n","          8.45807046e-02,  1.54063717e-01,  1.12338550e-01,\n","         -7.65244141e-02,  4.91280518e-02,  3.96742821e-02,\n","         -1.45121515e-01,  1.19953588e-01,  7.42163360e-02,\n","         -1.13956496e-01,  6.63054883e-02, -7.84708858e-02,\n","          1.22312881e-01,  1.06882431e-01,  2.75885593e-02,\n","         -5.45151345e-03, -9.03756917e-02,  1.22724168e-01,\n","          1.31920561e-01,  5.74101247e-02,  6.31859824e-02,\n","         -1.44468099e-01,  3.12954597e-02, -5.79852797e-02,\n","          9.76539925e-02, -9.90582258e-02,  5.48684932e-02,\n","          1.18582137e-01,  1.67561211e-02]],\n","\n","       [[ 6.96523711e-02,  9.51133072e-02,  3.83260548e-02,\n","         -5.53961545e-02, -3.67039323e-01, -3.79873882e-03,\n","         -3.77463698e-02, -9.33265090e-02,  1.11335084e-01,\n","          8.50162283e-02,  5.87407723e-02,  5.30881658e-02,\n","          7.25775864e-03,  1.02062315e-01,  1.43433124e-01,\n","         -5.78006804e-02, -1.19045444e-01, -6.00903966e-02,\n","          3.32476720e-02,  7.53503432e-03,  7.25210458e-02,\n","          8.00978243e-02,  1.55207552e-02, -4.05040830e-01,\n","          4.93789762e-02,  1.65580940e-02, -6.52524158e-02,\n","          3.23175006e-02, -4.22170609e-02,  7.45071156e-04,\n","          8.01340118e-02, -7.53863603e-02],\n","        [ 2.02840697e-02,  4.71455641e-02, -1.41292915e-01,\n","          1.82563402e-02, -3.87157440e-01,  1.26854047e-01,\n","          9.47140306e-02, -9.23017785e-03,  7.46181980e-02,\n","          1.12658747e-01,  9.80188772e-02,  3.21617983e-02,\n","         -9.01404843e-02,  7.28641152e-02,  1.64422423e-01,\n","          1.97462253e-02,  9.43850651e-02, -1.58866383e-02,\n","          9.64827016e-02, -2.40852106e-02, -5.61850928e-02,\n","          1.27013549e-01, -6.57607522e-03, -2.07259730e-01,\n","         -1.50331721e-01, -1.27493753e-03, -4.38441522e-03,\n","         -2.12110505e-02,  5.44657074e-02,  1.44705877e-01,\n","          1.71855316e-02, -5.53093432e-03],\n","        [-6.07071817e-02,  1.60668604e-02,  3.54671068e-02,\n","          5.38311750e-02, -1.24855854e-01, -7.43781449e-03,\n","         -8.82941037e-02,  3.41388993e-02, -8.64619464e-02,\n","         -4.48276363e-02,  9.23824310e-02,  2.69729225e-03,\n","         -1.37553453e-01, -1.03436284e-01, -5.36071211e-02,\n","         -4.97642271e-02,  1.19962431e-01, -1.03399716e-01,\n","         -1.26018226e-01, -6.87719975e-03,  6.22466095e-02,\n","         -6.42414344e-03,  1.09452598e-01, -2.88673013e-01,\n","         -8.79256576e-02,  3.01115997e-02, -1.15632243e-01,\n","         -1.09858334e-01,  8.04788321e-02,  3.90831679e-02,\n","          1.04585968e-01,  3.70089523e-02]]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"PMu91HFsOz49","colab_type":"code","colab":{}},"source":["for layer in full_model.layers[0:26]:\n","  layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"74kUfUMlO9kn","colab_type":"code","colab":{}},"source":["full_model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LylfRtwVPAeT","colab_type":"code","outputId":"7e16f2c2-7bb1-4380-c4c0-38985cba9ed8","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["full_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 64, 64, 3)         0         \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 64, 64, 32)        896       \n","_________________________________________________________________\n","batch_normalization_21 (Batc (None, 64, 64, 32)        128       \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 64, 64, 32)        9248      \n","_________________________________________________________________\n","batch_normalization_22 (Batc (None, 64, 64, 32)        128       \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_23 (Batc (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","conv2d_25 (Conv2D)           (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_24 (Batc (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_26 (Conv2D)           (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","batch_normalization_25 (Batc (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_28 (Conv2D)           (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","conv2d_29 (Conv2D)           (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv2d_30 (Conv2D)           (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 4, 4, 512)         2048      \n","_________________________________________________________________\n","conv2d_31 (Conv2D)           (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 4, 4, 512)         2048      \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               262272    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 160)               20640     \n","=================================================================\n","Total params: 5,003,072\n","Trainable params: 282,912\n","Non-trainable params: 4,720,160\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M15LrUfBPFDz","colab_type":"code","outputId":"f6ed1b22-71fd-4df3-92ab-474321eeab42","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["filepath = 'pretrained_voice_best_weights.h5'\n","checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n","callbacks_list = [checkpoint]\n","pretrained_classifier_train = full_model.fit(X_train, y_train, epochs = 100, batch_size = 256, verbose = 1, callbacks = callbacks_list, validation_data = [X_val, y_val])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 24000 samples, validate on 8000 samples\n","Epoch 1/100\n","24000/24000 [==============================] - 9s 357us/step - loss: 3.7740 - acc: 0.1778 - val_loss: 15.1648 - val_acc: 0.0000e+00\n","\n","Epoch 00001: val_acc improved from -inf to 0.00000, saving model to pretrained_voice_best_weights.h5\n","Epoch 2/100\n","24000/24000 [==============================] - 7s 310us/step - loss: 1.7077 - acc: 0.5806 - val_loss: 15.9731 - val_acc: 0.0000e+00\n","\n","Epoch 00002: val_acc did not improve from 0.00000\n","Epoch 3/100\n","24000/24000 [==============================] - 7s 312us/step - loss: 1.1715 - acc: 0.7096 - val_loss: 16.0168 - val_acc: 0.0000e+00\n","\n","Epoch 00003: val_acc did not improve from 0.00000\n","Epoch 4/100\n","24000/24000 [==============================] - 7s 310us/step - loss: 0.9724 - acc: 0.7602 - val_loss: 16.0321 - val_acc: 0.0000e+00\n","\n","Epoch 00004: val_acc did not improve from 0.00000\n","Epoch 5/100\n","24000/24000 [==============================] - 7s 309us/step - loss: 0.8616 - acc: 0.7831 - val_loss: 16.0553 - val_acc: 0.0000e+00\n","\n","Epoch 00005: val_acc did not improve from 0.00000\n","Epoch 6/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.7901 - acc: 0.8018 - val_loss: 16.0327 - val_acc: 0.0000e+00\n","\n","Epoch 00006: val_acc did not improve from 0.00000\n","Epoch 7/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.7351 - acc: 0.8149 - val_loss: 16.0427 - val_acc: 0.0000e+00\n","\n","Epoch 00007: val_acc did not improve from 0.00000\n","Epoch 8/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.6928 - acc: 0.8239 - val_loss: 16.0559 - val_acc: 0.0000e+00\n","\n","Epoch 00008: val_acc did not improve from 0.00000\n","Epoch 9/100\n","24000/24000 [==============================] - 7s 310us/step - loss: 0.6659 - acc: 0.8282 - val_loss: 16.0546 - val_acc: 0.0000e+00\n","\n","Epoch 00009: val_acc did not improve from 0.00000\n","Epoch 10/100\n","24000/24000 [==============================] - 7s 309us/step - loss: 0.6319 - acc: 0.8382 - val_loss: 16.0607 - val_acc: 0.0000e+00\n","\n","Epoch 00010: val_acc did not improve from 0.00000\n","Epoch 11/100\n","24000/24000 [==============================] - 7s 309us/step - loss: 0.6010 - acc: 0.8457 - val_loss: 16.0618 - val_acc: 0.0000e+00\n","\n","Epoch 00011: val_acc did not improve from 0.00000\n","Epoch 12/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.5782 - acc: 0.8508 - val_loss: 16.0620 - val_acc: 0.0000e+00\n","\n","Epoch 00012: val_acc did not improve from 0.00000\n","Epoch 13/100\n","24000/24000 [==============================] - 7s 310us/step - loss: 0.5582 - acc: 0.8555 - val_loss: 16.0618 - val_acc: 0.0000e+00\n","\n","Epoch 00013: val_acc did not improve from 0.00000\n","Epoch 14/100\n","24000/24000 [==============================] - 7s 311us/step - loss: 0.5303 - acc: 0.8617 - val_loss: 16.0685 - val_acc: 0.0000e+00\n","\n","Epoch 00014: val_acc did not improve from 0.00000\n","Epoch 15/100\n","24000/24000 [==============================] - 7s 310us/step - loss: 0.5045 - acc: 0.8696 - val_loss: 16.0656 - val_acc: 0.0000e+00\n","\n","Epoch 00015: val_acc did not improve from 0.00000\n","Epoch 16/100\n","24000/24000 [==============================] - 7s 310us/step - loss: 0.4855 - acc: 0.8722 - val_loss: 16.0674 - val_acc: 0.0000e+00\n","\n","Epoch 00016: val_acc did not improve from 0.00000\n","Epoch 17/100\n","24000/24000 [==============================] - 7s 309us/step - loss: 0.4664 - acc: 0.8792 - val_loss: 16.0664 - val_acc: 0.0000e+00\n","\n","Epoch 00017: val_acc did not improve from 0.00000\n","Epoch 18/100\n","24000/24000 [==============================] - 7s 309us/step - loss: 0.4522 - acc: 0.8815 - val_loss: 16.0792 - val_acc: 0.0000e+00\n","\n","Epoch 00018: val_acc did not improve from 0.00000\n","Epoch 19/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.4436 - acc: 0.8823 - val_loss: 16.0721 - val_acc: 0.0000e+00\n","\n","Epoch 00019: val_acc did not improve from 0.00000\n","Epoch 20/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.4202 - acc: 0.8896 - val_loss: 16.0756 - val_acc: 0.0000e+00\n","\n","Epoch 00020: val_acc did not improve from 0.00000\n","Epoch 21/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.4134 - acc: 0.8913 - val_loss: 16.0793 - val_acc: 0.0000e+00\n","\n","Epoch 00021: val_acc did not improve from 0.00000\n","Epoch 22/100\n","24000/24000 [==============================] - 7s 309us/step - loss: 0.3967 - acc: 0.8961 - val_loss: 16.0843 - val_acc: 0.0000e+00\n","\n","Epoch 00022: val_acc did not improve from 0.00000\n","Epoch 23/100\n","24000/24000 [==============================] - 7s 309us/step - loss: 0.3887 - acc: 0.8954 - val_loss: 16.0784 - val_acc: 0.0000e+00\n","\n","Epoch 00023: val_acc did not improve from 0.00000\n","Epoch 24/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.3723 - acc: 0.9023 - val_loss: 16.0828 - val_acc: 0.0000e+00\n","\n","Epoch 00024: val_acc did not improve from 0.00000\n","Epoch 25/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.3639 - acc: 0.9050 - val_loss: 16.0781 - val_acc: 0.0000e+00\n","\n","Epoch 00025: val_acc did not improve from 0.00000\n","Epoch 26/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.3494 - acc: 0.9107 - val_loss: 16.0850 - val_acc: 0.0000e+00\n","\n","Epoch 00026: val_acc did not improve from 0.00000\n","Epoch 27/100\n","24000/24000 [==============================] - 7s 310us/step - loss: 0.3353 - acc: 0.9123 - val_loss: 16.0903 - val_acc: 0.0000e+00\n","\n","Epoch 00027: val_acc did not improve from 0.00000\n","Epoch 28/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.3304 - acc: 0.9155 - val_loss: 16.0927 - val_acc: 0.0000e+00\n","\n","Epoch 00028: val_acc did not improve from 0.00000\n","Epoch 29/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.3129 - acc: 0.9187 - val_loss: 16.0933 - val_acc: 0.0000e+00\n","\n","Epoch 00029: val_acc did not improve from 0.00000\n","Epoch 30/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.3189 - acc: 0.9160 - val_loss: 16.0899 - val_acc: 0.0000e+00\n","\n","Epoch 00030: val_acc did not improve from 0.00000\n","Epoch 31/100\n","24000/24000 [==============================] - 7s 309us/step - loss: 0.3017 - acc: 0.9203 - val_loss: 16.0879 - val_acc: 0.0000e+00\n","\n","Epoch 00031: val_acc did not improve from 0.00000\n","Epoch 32/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.2876 - acc: 0.9261 - val_loss: 16.0967 - val_acc: 0.0000e+00\n","\n","Epoch 00032: val_acc did not improve from 0.00000\n","Epoch 33/100\n","24000/24000 [==============================] - 7s 309us/step - loss: 0.2898 - acc: 0.9242 - val_loss: 16.0932 - val_acc: 0.0000e+00\n","\n","Epoch 00033: val_acc did not improve from 0.00000\n","Epoch 34/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.2724 - acc: 0.9312 - val_loss: 16.0999 - val_acc: 0.0000e+00\n","\n","Epoch 00034: val_acc did not improve from 0.00000\n","Epoch 35/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.2684 - acc: 0.9309 - val_loss: 16.0956 - val_acc: 0.0000e+00\n","\n","Epoch 00035: val_acc did not improve from 0.00000\n","Epoch 36/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.2686 - acc: 0.9302 - val_loss: 16.0957 - val_acc: 0.0000e+00\n","\n","Epoch 00036: val_acc did not improve from 0.00000\n","Epoch 37/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.2589 - acc: 0.9310 - val_loss: 16.0997 - val_acc: 0.0000e+00\n","\n","Epoch 00037: val_acc did not improve from 0.00000\n","Epoch 38/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.2460 - acc: 0.9382 - val_loss: 16.0986 - val_acc: 0.0000e+00\n","\n","Epoch 00038: val_acc did not improve from 0.00000\n","Epoch 39/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.2341 - acc: 0.9401 - val_loss: 16.0975 - val_acc: 0.0000e+00\n","\n","Epoch 00039: val_acc did not improve from 0.00000\n","Epoch 40/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.2359 - acc: 0.9396 - val_loss: 16.1051 - val_acc: 0.0000e+00\n","\n","Epoch 00040: val_acc did not improve from 0.00000\n","Epoch 41/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.2303 - acc: 0.9387 - val_loss: 16.1018 - val_acc: 0.0000e+00\n","\n","Epoch 00041: val_acc did not improve from 0.00000\n","Epoch 42/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.2242 - acc: 0.9411 - val_loss: 16.0994 - val_acc: 0.0000e+00\n","\n","Epoch 00042: val_acc did not improve from 0.00000\n","Epoch 43/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.2203 - acc: 0.9430 - val_loss: 16.1035 - val_acc: 0.0000e+00\n","\n","Epoch 00043: val_acc did not improve from 0.00000\n","Epoch 44/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.2127 - acc: 0.9453 - val_loss: 16.1060 - val_acc: 0.0000e+00\n","\n","Epoch 00044: val_acc did not improve from 0.00000\n","Epoch 45/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.2097 - acc: 0.9453 - val_loss: 16.1013 - val_acc: 0.0000e+00\n","\n","Epoch 00045: val_acc did not improve from 0.00000\n","Epoch 46/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.2002 - acc: 0.9491 - val_loss: 16.1054 - val_acc: 0.0000e+00\n","\n","Epoch 00046: val_acc did not improve from 0.00000\n","Epoch 47/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.1967 - acc: 0.9491 - val_loss: 16.1056 - val_acc: 0.0000e+00\n","\n","Epoch 00047: val_acc did not improve from 0.00000\n","Epoch 48/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1816 - acc: 0.9540 - val_loss: 16.1082 - val_acc: 0.0000e+00\n","\n","Epoch 00048: val_acc did not improve from 0.00000\n","Epoch 49/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.1752 - acc: 0.9583 - val_loss: 16.1085 - val_acc: 0.0000e+00\n","\n","Epoch 00049: val_acc did not improve from 0.00000\n","Epoch 50/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1888 - acc: 0.9503 - val_loss: 16.1094 - val_acc: 0.0000e+00\n","\n","Epoch 00050: val_acc did not improve from 0.00000\n","Epoch 51/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.1788 - acc: 0.9547 - val_loss: 16.1076 - val_acc: 0.0000e+00\n","\n","Epoch 00051: val_acc did not improve from 0.00000\n","Epoch 52/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.1698 - acc: 0.9571 - val_loss: 16.1078 - val_acc: 0.0000e+00\n","\n","Epoch 00052: val_acc did not improve from 0.00000\n","Epoch 53/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1713 - acc: 0.9561 - val_loss: 16.1085 - val_acc: 0.0000e+00\n","\n","Epoch 00053: val_acc did not improve from 0.00000\n","Epoch 54/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1638 - acc: 0.9588 - val_loss: 16.1095 - val_acc: 0.0000e+00\n","\n","Epoch 00054: val_acc did not improve from 0.00000\n","Epoch 55/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.1594 - acc: 0.9597 - val_loss: 16.1090 - val_acc: 0.0000e+00\n","\n","Epoch 00055: val_acc did not improve from 0.00000\n","Epoch 56/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.1564 - acc: 0.9601 - val_loss: 16.1107 - val_acc: 0.0000e+00\n","\n","Epoch 00056: val_acc did not improve from 0.00000\n","Epoch 57/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.1544 - acc: 0.9600 - val_loss: 16.1107 - val_acc: 0.0000e+00\n","\n","Epoch 00057: val_acc did not improve from 0.00000\n","Epoch 58/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1489 - acc: 0.9632 - val_loss: 16.1102 - val_acc: 0.0000e+00\n","\n","Epoch 00058: val_acc did not improve from 0.00000\n","Epoch 59/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.1418 - acc: 0.9646 - val_loss: 16.1097 - val_acc: 0.0000e+00\n","\n","Epoch 00059: val_acc did not improve from 0.00000\n","Epoch 60/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.1392 - acc: 0.9652 - val_loss: 16.1106 - val_acc: 0.0000e+00\n","\n","Epoch 00060: val_acc did not improve from 0.00000\n","Epoch 61/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.1418 - acc: 0.9645 - val_loss: 16.1106 - val_acc: 0.0000e+00\n","\n","Epoch 00061: val_acc did not improve from 0.00000\n","Epoch 62/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1393 - acc: 0.9636 - val_loss: 16.1094 - val_acc: 0.0000e+00\n","\n","Epoch 00062: val_acc did not improve from 0.00000\n","Epoch 63/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1297 - acc: 0.9683 - val_loss: 16.1133 - val_acc: 0.0000e+00\n","\n","Epoch 00063: val_acc did not improve from 0.00000\n","Epoch 64/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.1237 - acc: 0.9705 - val_loss: 16.1134 - val_acc: 0.0000e+00\n","\n","Epoch 00064: val_acc did not improve from 0.00000\n","Epoch 65/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.1193 - acc: 0.9726 - val_loss: 16.1120 - val_acc: 0.0000e+00\n","\n","Epoch 00065: val_acc did not improve from 0.00000\n","Epoch 66/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1255 - acc: 0.9682 - val_loss: 16.1141 - val_acc: 0.0000e+00\n","\n","Epoch 00066: val_acc did not improve from 0.00000\n","Epoch 67/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.1197 - acc: 0.9704 - val_loss: 16.1133 - val_acc: 0.0000e+00\n","\n","Epoch 00067: val_acc did not improve from 0.00000\n","Epoch 68/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.1266 - acc: 0.9673 - val_loss: 16.1135 - val_acc: 0.0000e+00\n","\n","Epoch 00068: val_acc did not improve from 0.00000\n","Epoch 69/100\n","24000/24000 [==============================] - 7s 307us/step - loss: 0.1275 - acc: 0.9664 - val_loss: 16.1138 - val_acc: 0.0000e+00\n","\n","Epoch 00069: val_acc did not improve from 0.00000\n","Epoch 70/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.1171 - acc: 0.9686 - val_loss: 16.1147 - val_acc: 0.0000e+00\n","\n","Epoch 00070: val_acc did not improve from 0.00000\n","Epoch 71/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1081 - acc: 0.9734 - val_loss: 16.1144 - val_acc: 0.0000e+00\n","\n","Epoch 00071: val_acc did not improve from 0.00000\n","Epoch 72/100\n","24000/24000 [==============================] - 7s 308us/step - loss: 0.1100 - acc: 0.9727 - val_loss: 16.1145 - val_acc: 0.0000e+00\n","\n","Epoch 00072: val_acc did not improve from 0.00000\n","Epoch 73/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.1008 - acc: 0.9767 - val_loss: 16.1143 - val_acc: 0.0000e+00\n","\n","Epoch 00073: val_acc did not improve from 0.00000\n","Epoch 74/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.1045 - acc: 0.9753 - val_loss: 16.1149 - val_acc: 0.0000e+00\n","\n","Epoch 00074: val_acc did not improve from 0.00000\n","Epoch 75/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.1057 - acc: 0.9738 - val_loss: 16.1157 - val_acc: 0.0000e+00\n","\n","Epoch 00075: val_acc did not improve from 0.00000\n","Epoch 76/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.0972 - acc: 0.9769 - val_loss: 16.1152 - val_acc: 0.0000e+00\n","\n","Epoch 00076: val_acc did not improve from 0.00000\n","Epoch 77/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0955 - acc: 0.9764 - val_loss: 16.1159 - val_acc: 0.0000e+00\n","\n","Epoch 00077: val_acc did not improve from 0.00000\n","Epoch 78/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.0875 - acc: 0.9799 - val_loss: 16.1149 - val_acc: 0.0000e+00\n","\n","Epoch 00078: val_acc did not improve from 0.00000\n","Epoch 79/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.0847 - acc: 0.9812 - val_loss: 16.1160 - val_acc: 0.0000e+00\n","\n","Epoch 00079: val_acc did not improve from 0.00000\n","Epoch 80/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.0810 - acc: 0.9831 - val_loss: 16.1149 - val_acc: 0.0000e+00\n","\n","Epoch 00080: val_acc did not improve from 0.00000\n","Epoch 81/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.0931 - acc: 0.9771 - val_loss: 16.1153 - val_acc: 0.0000e+00\n","\n","Epoch 00081: val_acc did not improve from 0.00000\n","Epoch 82/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0903 - acc: 0.9781 - val_loss: 16.1155 - val_acc: 0.0000e+00\n","\n","Epoch 00082: val_acc did not improve from 0.00000\n","Epoch 83/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0868 - acc: 0.9791 - val_loss: 16.1159 - val_acc: 0.0000e+00\n","\n","Epoch 00083: val_acc did not improve from 0.00000\n","Epoch 84/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0825 - acc: 0.9795 - val_loss: 16.1153 - val_acc: 0.0000e+00\n","\n","Epoch 00084: val_acc did not improve from 0.00000\n","Epoch 85/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0886 - acc: 0.9773 - val_loss: 16.1158 - val_acc: 0.0000e+00\n","\n","Epoch 00085: val_acc did not improve from 0.00000\n","Epoch 86/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.0807 - acc: 0.9797 - val_loss: 16.1162 - val_acc: 0.0000e+00\n","\n","Epoch 00086: val_acc did not improve from 0.00000\n","Epoch 87/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.0841 - acc: 0.9792 - val_loss: 16.1159 - val_acc: 0.0000e+00\n","\n","Epoch 00087: val_acc did not improve from 0.00000\n","Epoch 88/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0719 - acc: 0.9838 - val_loss: 16.1159 - val_acc: 0.0000e+00\n","\n","Epoch 00088: val_acc did not improve from 0.00000\n","Epoch 89/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.0751 - acc: 0.9819 - val_loss: 16.1166 - val_acc: 0.0000e+00\n","\n","Epoch 00089: val_acc did not improve from 0.00000\n","Epoch 90/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0816 - acc: 0.9795 - val_loss: 16.1155 - val_acc: 0.0000e+00\n","\n","Epoch 00090: val_acc did not improve from 0.00000\n","Epoch 91/100\n","24000/24000 [==============================] - 7s 303us/step - loss: 0.0807 - acc: 0.9792 - val_loss: 16.1167 - val_acc: 0.0000e+00\n","\n","Epoch 00091: val_acc did not improve from 0.00000\n","Epoch 92/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0775 - acc: 0.9805 - val_loss: 16.1162 - val_acc: 0.0000e+00\n","\n","Epoch 00092: val_acc did not improve from 0.00000\n","Epoch 93/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.0671 - acc: 0.9842 - val_loss: 16.1167 - val_acc: 0.0000e+00\n","\n","Epoch 00093: val_acc did not improve from 0.00000\n","Epoch 94/100\n","24000/24000 [==============================] - 7s 304us/step - loss: 0.0671 - acc: 0.9851 - val_loss: 16.1163 - val_acc: 0.0000e+00\n","\n","Epoch 00094: val_acc did not improve from 0.00000\n","Epoch 95/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0609 - acc: 0.9875 - val_loss: 16.1164 - val_acc: 0.0000e+00\n","\n","Epoch 00095: val_acc did not improve from 0.00000\n","Epoch 96/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0598 - acc: 0.9871 - val_loss: 16.1162 - val_acc: 0.0000e+00\n","\n","Epoch 00096: val_acc did not improve from 0.00000\n","Epoch 97/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0703 - acc: 0.9823 - val_loss: 16.1163 - val_acc: 0.0000e+00\n","\n","Epoch 00097: val_acc did not improve from 0.00000\n","Epoch 98/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0756 - acc: 0.9791 - val_loss: 16.1165 - val_acc: 0.0000e+00\n","\n","Epoch 00098: val_acc did not improve from 0.00000\n","Epoch 99/100\n","24000/24000 [==============================] - 7s 305us/step - loss: 0.0719 - acc: 0.9809 - val_loss: 16.1166 - val_acc: 0.0000e+00\n","\n","Epoch 00099: val_acc did not improve from 0.00000\n","Epoch 100/100\n","24000/24000 [==============================] - 7s 306us/step - loss: 0.0647 - acc: 0.9841 - val_loss: 16.1169 - val_acc: 0.0000e+00\n","\n","Epoch 00100: val_acc did not improve from 0.00000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SzJsn3UMPWYU","colab_type":"code","colab":{}},"source":["full_model.save_weights('full_model_pretrained_voices_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"omyvuOLOPyfi","colab_type":"code","outputId":"3e0ffcfc-eb03-42ba-d630-b39be77d4ef6","colab":{"base_uri":"https://localhost:8080/","height":545}},"source":["accuracy = pretrained_classifier_train.history['acc']\n","val_accuracy = pretrained_classifier_train.history['val_acc']\n","loss = pretrained_classifier_train.history['loss']\n","val_loss = pretrained_classifier_train.history['val_loss']\n","epochs = range(len(accuracy))\n","plt.plot(epochs, accuracy, 'bo', label = 'Training Accuracy')\n","plt.plot(epochs, val_accuracy, 'b', label = 'Validation Accuracy')\n","plt.title('Training and Validation Accuracy using Pretrained Autoencoder Weights')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, 'bo', label = 'Training Loss')\n","plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n","plt.title('Training and Validation Loss using Pretrained Autoencoder Weights')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAcIAAAEICAYAAADMa/SXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUQk0f4/Dgs5HwkbFlEAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAaYAAAEICAYAAAAUZ1CdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"GMHN43-aP755","colab_type":"code","colab":{}},"source":["test_eval = full_model.evaluate(X_test, y_test, verbose = 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMBHk7P0QSoi","colab_type":"code","outputId":"f6e22a9d-878e-4898-bbb5-def969e2aaa4","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print('Test loss : ', test_eval[0])\n","print('Test accuracy : ', test_eval[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test loss :  5.114871261536609\n","Test accuracy :  0.56575\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h9Ov2gKCQaJN","colab_type":"code","colab":{}},"source":["predicted_classes = full_model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgLGVxxcQg8K","colab_type":"code","colab":{}},"source":["predicted_classes = np.argmax(np.round(predicted_classes), axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_AOOeqN7QlIr","colab_type":"code","colab":{}},"source":["test_df['predicted_classes'] = predicted_classes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QE3LK1_WQ7zk","colab_type":"code","outputId":"4f352284-b7b2-485e-b88e-01c570fd34bf","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["test_df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_labels</th>\n","      <th>predicted_classes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>89</td>\n","      <td>159</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>89</td>\n","      <td>159</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>89</td>\n","      <td>159</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>89</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>89</td>\n","      <td>159</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  test_labels  predicted_classes\n","0          89                159\n","1          89                159\n","2          89                159\n","3          89                 51\n","4          89                159"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"UDMlwpiGREgM","colab_type":"code","outputId":"290e3962-2e97-4ed6-cba1-811881352e72","colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["test_df[test_df['test_labels'] != test_df['predicted_classes']]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_labels</th>\n","      <th>predicted_classes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>89</td>\n","      <td>159</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>89</td>\n","      <td>159</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>89</td>\n","      <td>159</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>89</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>89</td>\n","      <td>159</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7995</th>\n","      <td>1585</td>\n","      <td>120</td>\n","    </tr>\n","    <tr>\n","      <th>7996</th>\n","      <td>1585</td>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>7997</th>\n","      <td>1585</td>\n","      <td>89</td>\n","    </tr>\n","    <tr>\n","      <th>7998</th>\n","      <td>1585</td>\n","      <td>92</td>\n","    </tr>\n","    <tr>\n","      <th>7999</th>\n","      <td>1585</td>\n","      <td>93</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8000 rows × 2 columns</p>\n","</div>"],"text/plain":["     test_labels  predicted_classes\n","0             89                159\n","1             89                159\n","2             89                159\n","3             89                 51\n","4             89                159\n","...          ...                ...\n","7995        1585                120\n","7996        1585                 76\n","7997        1585                 89\n","7998        1585                 92\n","7999        1585                 93\n","\n","[8000 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"QrraYWvkRXTQ","colab_type":"code","outputId":"74e008fd-fa1e-4d01-9efc-729e043f48a1","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["1-round(len(test_df[test_df['test_labels'] != test_df['predicted_classes']])/len(test_df),3)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"9BiH8XsSRtnQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}